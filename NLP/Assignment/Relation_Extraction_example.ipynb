{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relation Extraction example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AujKplf8RR-"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZYVfkk3Qpn5"
      },
      "source": [
        "---\n",
        "\n",
        "Example on `ieer` corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_biZieU68X3m",
        "outputId": "c06b154d-dd11-4eff-d6bd-6379cb0dcb1c"
      },
      "source": [
        "import re, nltk\n",
        "\n",
        "# Search for strings that contain the word \"in\".\n",
        "\n",
        "# \\b matches the empty string, but only at the beginning or end of a word. (b = boundary)\n",
        "'''Negative lookahead assertion(?<= ...). Matches if ... doesnt match next. \n",
        "To disregard the strings such as success in supervising, where in is followed by a gerund.'''\n",
        "\n",
        "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing\\b)')\n",
        "\n",
        "# Using the documents from the IEEE Corpus - New York Times, 15 March 1998.\n",
        "# (see details here: http://www.nltk.org/_modules/nltk/corpus/reader/ieer.html)\n",
        "docs = nltk.corpus.ieer.parsed_docs('NYT_19980315')\n",
        "\n",
        "for doc in docs:\n",
        "  for rel in nltk.sem.relextract.extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern=IN):\n",
        "    print(nltk.sem.relextract.rtuple(rel))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
            "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
            "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
            "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
            "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
            "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
            "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
            "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
            "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
            "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
            "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
            "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
            "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5qKBsQhRDGH"
      },
      "source": [
        "---\n",
        "Example on a custom corpus from NLTK library, which does appear to work fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJOC71vLATe7",
        "outputId": "3f1c6a03-ea93-4b06-d678-78e621cf0ba3"
      },
      "source": [
        "ROLE = re.compile(r'.*(chairman|president|trader|scientist|economist|analyst|partner).*')\n",
        "rels = []\n",
        "for i, sent in enumerate(nltk.corpus.treebank.tagged_sents()[:1500]):\n",
        "    sent = nltk.ne_chunk(sent)\n",
        "    rels = nltk.sem.relextract.extract_rels('PER', 'ORG', sent, corpus='ace', pattern=ROLE, window=7)\n",
        "    for rel in rels:\n",
        "        print('{0:<5}{1}'.format(i, nltk.sem.relextract.rtuple(rel)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    [PER: 'Vinken/NNP'] 'is/VBZ chairman/NN of/IN' [ORG: 'Elsevier/NNP']\n",
            "254  [PER: 'Shugart/NNP'] ',/, currently/RB chairman/NN of/IN' [ORG: 'Seagate/NNP Technology/NNP']\n",
            "325  [PER: 'George/NNP Foot/NNP'] ',/, a/DT managing/VBG partner/NN at/IN' [ORG: 'Newgate/NNP Management/NNP Associates/NNP']\n",
            "331  [PER: 'Michael/NNP Porter/NNP'] ',/, an/DT analyst/NN at/IN' [ORG: 'Smith/NNP Barney/NNP']\n",
            "391  [PER: 'Elliott/NNP Platt/NNP'] ',/, an/DT economist/NN at/IN' [ORG: 'Donaldson/NNP']\n",
            "485  [PER: 'Arafat/NNP'] 'has/VBZ written/VBN to/TO the/DT chairman/NN of/IN the/DT' [ORG: 'International/NNP']\n",
            "624  [PER: 'Stephen/NNP Salmore/NNP'] ',/, a/DT political/JJ scientist/NN at/IN' [ORG: 'New/NNP Jersey/NNP']\n",
            "891  [PER: 'George/NNP Jennison/NNP'] ',/, head/JJ trader/NN of/IN banking/NN issues/NNS in/IN' [ORG: 'Shearson/NNP']\n",
            "928  [PER: 'Neal/NNP R./NNP Sonnett/NNP'] ',/, president/NN of/IN the/DT' [ORG: 'National/NNP Association/NNP']\n",
            "1065 [PER: 'Michael/NNP Stark/NNP'] ',/, chip/NN analyst/NN at/IN' [ORG: 'Robertson/NNP']\n",
            "1081 [PER: 'Douglas/NNP Madison/NNP'] ',/, a/DT corporate/JJ trader/NN with/IN' [ORG: 'Bank/NNP']\n",
            "1200 [PER: 'Chuck/NNP Hurley/NNP'] ',/, vice/NN president/NN of/IN communications/NNS for/IN the/DT' [ORG: 'Insurance/NNP Institute/NNP']\n",
            "1224 [PER: 'Richard/NNP Driscoll/NNP'] ',/, vice/NN chairman/NN of/IN' [ORG: 'Bank/NNP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOIxs27QzaJ"
      },
      "source": [
        "---\n",
        "\n",
        "Example on a custom sentence. (This doesn't find any relations)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzQPi8UA9UwE",
        "outputId": "7016e0dd-38ff-48f6-87f2-17e17de129ec"
      },
      "source": [
        "WORK = re.compile(r'.*\\bworks\\b.*')\n",
        "\n",
        "sent = 'Tom works with James.'\n",
        "tokenized_sent = nltk.word_tokenize(sent)\n",
        "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
        "chunked = nltk.ne_chunk(tagged_sent)\n",
        "\n",
        "nltk.sem.relextract.extract_rels('PER', 'PER', chunked, corpus='ace', pattern=WORK)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esw-CQvPRlqq"
      },
      "source": [
        "---\n",
        "\n",
        "Example on a custom sentence. (This finds the relation correctly)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ObxR2hRiTq",
        "outputId": "3914d842-ddbf-4005-a48f-b08f929a351f"
      },
      "source": [
        "sent = 'Tom works with James.'\n",
        "tokenized_sent = nltk.word_tokenize(sent)\n",
        "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
        "chunked = nltk.ne_chunk(tagged_sent)\n",
        "\n",
        "subjclass = 'PERSON'\n",
        "objclass = 'PERSON'\n",
        "pattern = re.compile(r'.*\\bworks\\b.*')\n",
        "\n",
        "# Group a chunk structure into a list of 'semi-relations'.\n",
        "pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "# Convert 'semi-relations' into a dictionary which stores information \n",
        "# about the subject and object NEs plus the filler between them.\n",
        "reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "# Filter relevant relations by matching the regexp pattern.\n",
        "relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == objclass)\n",
        "rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "# Print the relations found in the text.\n",
        "for rel in rels:\n",
        "  print(nltk.sem.relextract.rtuple(rel))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PER: 'Tom/NNP'] 'works/VBZ with/IN' [PER: 'James/NNP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgJdQ0H2RxKC"
      },
      "source": [
        "---\n",
        "\n",
        "Another example on a custom sentence. (This correctly doesn't find any relations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl_3B_LpA74I"
      },
      "source": [
        "sent = 'Tom works at Microsoft.'\n",
        "tokenized_sent = nltk.word_tokenize(sent)\n",
        "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
        "chunked = nltk.ne_chunk(tagged_sent)\n",
        "\n",
        "subjclass = 'PERSON'\n",
        "objclass = 'PERSON'\n",
        "pattern = re.compile(r'.*\\bworks\\b.*')\n",
        "\n",
        "# Group a chunk structure into a list of 'semi-relations'.\n",
        "pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "# Convert 'semi-relations' into a dictionary which stores information \n",
        "# about the subject and object NEs plus the filler between them.\n",
        "reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "# Filter relevant relations by matching the regexp pattern.\n",
        "relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == objclass)\n",
        "rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "# Print the relations found in the text.\n",
        "for rel in rels:\n",
        "  print(nltk.sem.relextract.rtuple(rel))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENTWah5fOuSc"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}