{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CT5120/CT5146 - Assignment 1","provenance":[{"file_id":"12crGPce24mcgITZPs7hU_9CPnLAcyIq6","timestamp":1603097790764}]},"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit","metadata":{"interpreter":{"hash":"4e2712cae0285d6127848876a75df6f73cf9374065dfb3dd22b6d27093fb1c65"}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"2oP1uun77cIh"},"source":["# Assignment 1\n","\n","This assignment will involve the creation of a spellchecking system and an evaluation of its performance. You may use the code snippets provided in Python for completing this or you may use the programming language or environment of your choice\n","\n","Please start by downloading the corpus `holbrook.txt` from Blackboard\n","\n","The file consists of lines of text, with one sentence per line. Errors in the line are marked with a `|` as follows\n","\n","    My siter|sister go|goes to Tonbury .\n","    \n","In this case the word 'siter' was corrected to 'sister' and the word 'go' was corrected to 'goes'.\n","\n","In some places in the corpus two words maybe corrected to a single word or one word to a multiple words. This is denoted in the data using underscores e.g.,\n","\n","    My Mum goes out some_times|sometimes .\n","    \n","For the purpose of this assignment you do not need to separate these words, but instead you may treat them like a single token.\n","\n","*Note: you may use any functions from NLTK to complete the assignment. It should not be necessary to use other libraries and so please consult with us if your solution involves any other external library. If you use any function from NLTK in Task 6 please include a brief description of this function and how it contributes to your solution.*\n","\n","\n","\n","### Name - TAPAN AUTI\n","\n","### Class  - MSc Artificial Intelligence (1MAI1)\n","\n","### Student ID - 20231499"]},{"cell_type":"markdown","metadata":{"id":"TIVCSJV-7kDs"},"source":["## Task 1 (10 Marks)\n","\n","Write a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n","\n","Then split your data into a test set of 100 lines and a training set."]},{"cell_type":"code","metadata":{"id":"RznCZ1mw7mfk","tags":[]},"source":["import nltk\n","#storing all lines from text holbrook\n","lines = []  \n","with open('holbrook.txt', 'r',encoding='utf-8') as f:\n","    lines = f.readlines()\n","#storing dictionary values\n","data = []\n","\n","#the following code stores the coorected sentence in corrected list and original sentence in original list and counts the indexes of changes.\n","for line in lines:\n","    original = []\n","    corrected = []\n","    indexes = []\n","    count = 0\n","    l = line.split()\n","    for word in l:       \n","        if '|' in word:\n","            var = word.split('|')\n","            original.append(var[0])\n","            corrected.append(var[1])\n","            indexes.append(count)\n","        else:\n","            original.append(word)\n","            corrected.append(word)\n","        count += 1\n","    data.append({'original':original, 'corrected':corrected, 'indexes':indexes})\n","\n","print(data[2])    \n","    \n","\n","# Write your code here\n","\n","#assert(data[2] == {\n","#    'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], \n","#    'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], \n","#    'indexes': [9]\n","#})"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["{'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], 'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], 'indexes': [9]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"eRSX4I0H7pSC"},"source":["The counts and assertions given in the following sections are based on splitting the training and test set as follows"]},{"cell_type":"code","metadata":{"id":"Kt9aR2Gy7p1C"},"source":["#spilting the original and the test data into corrected and original \n","test = data[:100]\n","train = data[100:]\n","train_corrected = [i['corrected'] for i in train]\n","train_original = [i['original'] for i in train]\n","test_corrected = [i['corrected'] for i in test]\n","test_original = [i['original'] for i in test]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hm5JL7cH7sLK"},"source":["## **Task 2** (10 Marks): \n","Calculate the frequency (number of occurrences), *ignoring case*, of all words and their unigram probability from the corrected *training* sentences.\n","\n","*Hint: use `Counter` to implement this so it may be called many times*"]},{"cell_type":"code","metadata":{"id":"7ge0uHS-7uEK","tags":["outputPrepend"]},"source":["from collections import Counter\n","\n","import itertools\n","\n","#this function tokenises the corrected sentences from the training data\n","def seperation():\n","    test = data[:100]\n","    train = data[100:]\n","    train_corrected = [i['corrected'] for i in train]\n","    train_tokenize = (list(itertools.chain.from_iterable(train_corrected)))\n","    return train_tokenize\n","\n","# This function counts the unigram frequency\n","def unigram(word):\n","    train_tokenize = seperation()\n","    counter = Counter(train_tokenize)\n","    ans = counter[f\"{word}\"]\n","    return ans\n","     \n","#Tiis functions counts the probability of the unigram\n","def prob(word):\n","    train_tokenize = seperation()\n","    length = len(train_tokenize)\n","    Prob = unigram(word)/length\n","    return Prob\n","\n","def main():\n","    u = unigram('me')\n","\n","    p = prob('me')\n","\n","    return u,p\n","\n","main()\n","\n","\n","\n","#If you want to get all words count then use the below code--\n","\n","# train_tokenise = list(set(seperation()))\n","# counter = Counter(train_tokenize)\n","# for i in train_tokenise: \n","#     ans = counter[f\"{i}\"]\n","#     print(i,ans)\n","\n","\n","# Test your code with the following\n","#assert(unigram(\"me\")==87)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[", 'moved': 2, 'HE': 2, 'America': 2, 'Paul': 2, 'California': 2, 'flames': 2, 'loaded': 2, 'turned': 2, 'america': 2, 'York': 2, 'dear': 2, 'worry': 2, 'england': 2, 'daughter': 2, 'heart': 2, 'awful': 2, 'everything': 2, 'weekends': 2, 'kinds': 2, 'boss': 2, 'owns': 2, 'cow': 2, 'loads': 2, 'lame': 2, 'feed': 2, 'bran': 2, \"couldn't\": 2, \"isn't\": 2, 'gate': 2, 'cart': 2, 'ought': 2, 'seventeen': 2, 'flowers': 2, 'hallo': 2, 'Harison': 2, 'shine': 2, 'join': 2, 'beginning': 2, 'mole': 2, 'built': 2, 'summer': 2, 'die': 2, 'frog': 2, 'spawn': 2, 'cool': 2, 'bigger': 2, 'eggs': 2, 'jar': 2, 'weed': 2, 'tip': 2, 'rough': 2, 'read': 2, 'curtains': 2, 'explore': 2, 'rowing': 2, 'skeleton': 2, 'disappeared': 2, 'wondered': 2, 'plan': 2, 'ourselves': 2, 'treasure': 2, 'creepy': 2, 'tower': 2, 'finger': 2, 'sharp': 2, 'washed': 2, 'somewhere': 2, 'ask': 2, 'washing': 2, 'Dead': 2, 'Kitty': 2, 'Forged': 2, 'Note': 2, 'Be': 2, 'PLENTY': 2, \"Frogmen's\": 2, 'rex': 2, 'Jacket': 2, 'alone': 2, 'bus': 2, 'harbour': 2, 'hours': 2, 'china': 2, 'i': 2, 'distance': 2, 'fellow': 2, 'ears': 2, 'prick': 2, 'bags': 2, 'rubbish': 2, 'runway': 2, 'bins': 2, 'eats': 2, 'worth': 2, 'sees': 2, 'chimpanzee': 2, 'Dad': 2, \"won't\": 2, 'ice-cream': 2, 'alley': 2, 'switched': 2, 'park': 2, 'belongs': 2, 'Butcher': 2, 'Tate': 2, 'van': 2, 'lamb': 2, 'chop': 2, 'Gordon': 2, 'Ariel': 2, 'today': 2, \"what's\": 2, 'ah': 2, 'OK': 2, 'enjoy': 2, 'camp': 2, 'Pauline': 2, 'owned': 2, 'ours': 2, 'calm': 2, 'roaming': 2, 'Comment_allez-vous': 2, 'ma': 2, \"J'aime\": 2, '!': 2, 'beau': 2, 'belle': 2, 'Lawton': 2, 'taught': 2, 'Judith': 2, 'Auntie': 2, 'Clint': 2, 'Russ': 2, 'Conway': 2, 'Tenderfoot': 2, 'bedroom': 2, 'played': 2, 'impulse': 2, 'inhibition': 2, 'wearing': 2, 'sad': 2, 'even': 2, 'sir': 2, 'cake': 2, 'Bernard': 2, 'mice': 2, 'Guildwell': 2, 'quarrel': 2, 'Bronco': 2, 'ROSEMARY': 2, 'BERNARD': 2, \"I'd\": 2, 'Restaurant': 2, 'Chorus': 2, 'weary': 2, 'singing': 2, 'blues': 2, 'April': 2, 'August': 2, 'weasel': 2, 'gamekeeper': 2, 'soft': 2, 'teaching': 2, 'spellings': 2, 'difficult': 2, 'written': 2, 'popular': 1, 'Hospital': 1, 'Rider': 1, 'spun': 1, 'blowing': 1, 'sand': 1, 'oil': 1, 'slippery': 1, 'dry': 1, 'final': 1, \"they're\": 1, 'BSA': 1, 'bend': 1, \"he's\": 1, 'won': 1, 'toes': 1, 'shone': 1, 'yesterday': 1, 'thorns': 1, 'ducks': 1, 'pathway': 1, 'heavy': 1, 'muddy': 1, 'pearls': 1, 'foot': 1, 'touched': 1, 'JOAN': 1, 'STALL': 1, '54': 1, 'poem': 1, 'sill': 1, 'hopped': 1, 'popped': 1, 'chirped': 1, 'golden': 1, 'DENNIS': 1, 'Goodbye': 1, 'happen': 1, 'pips': 1, 'burn': 1, 'earwigs': 1, 'pockets': 1, 'cookers': 1, 'hairdresser': 1, 'twenty_one': 1, 'Butlins': 1, 'sculpture': 1, 'Chalmers': 1, 'real': 1, 'block': 1, 'modelled': 1, 'clay': 1, 'Swan': 1, 'upping': 1, 'calmer': 1, 'waters': 1, 'carefully': 1, 'Boats': 1, 'cruel': 1, 'stamp': 1, 'carrying': 1, 'Boat': 1, 'Wings': 1, 'swans': 1, 'delicate': 1, 'temper': 1, 'spent': 1, \"daren't\": 1, 'lays': 1, 'Waiting': 1, 'Sighing': 1, 'hearts': 1, 'Crying': 1, 'Hearts': 1, 'beating': 1, 'rapidly': 1, \"you've\": 1, 'choosing': 1, 'slammed': 1, 'hello': 1, 'decision': 1, 'Talk': 1, \"There's\": 1, 'hand': 1, 'scream': 1, 'scares': 1, \"Don't\": 1, 'silly': 1, \"You're\": 1, 'doll': 1, 'character': 1, 'asking': 1, \"She's\": 1, \"boyfriend's\": 1, \"Let's\": 1, 'Road': 1, 'Nr': 1, '21': 1, 'November': 1, 'such': 1, 'speak': 1, 'GEORGE': 1, 'GREEN': 1, '62': 1, 'BlinD': 1, 'visor': 1, 'factory': 1, 'Watson': 1, 'excited': 1, 'healthy': 1, 'fit': 1, 'unhealthy': 1, \"pigs'\": 1, 'FOOL': 1, 'pray': 1, 'forbear': 1, 'parent': 1, 'sport': 1, 'advance': 1, 'rise': 1, 'estate': 1, 'toll': 1, 'Lord': 1, 'receive': 1, 'soul': 1, 'THEN': 1, 'fool': 1, 'dancers': 1, 'swords': 1, 'following': 1, 'purple': 1, 'gore': 1, 'pint': 1, 'streets': 1, 'Redex': 1, 'Young': 1, 'POEM': 1, 'OF': 1, 'confide': 1, 'daffodils': 1, 'big-headed': 1, 'grip': 1, 'Teddy_boys': 1, 'Can': 1, 'sweetest': 1, 'Goods': 1, 'questioned': 1, 'club': 1, 'Tony': 1, 'queen': 1, 'Phil': 1, 'Q': 1, 'liner': 1, 'Thieves': 1, 'steal': 1, 'shook': 1, 'bowl': 1, 'sweets': 1, 'Jon': 1, 'guilty': 1, 'Murder': 1, 'serve': 1, '25': 1, 'tramps': 1, 'Walking': 1, 'rotter': 1, 'HoLBook': 1, 'needs': 1, 'haircut': 1, 'shirt': 1, 'beady': 1, 'heath': 1, 'chase': 1, 'gaining': 1, 'shooting': 1, 'January': 1, 'identify': 1, 'sergeant': 1, 'MAY': 1, 'GiRL': 1, 'An': 1, 'Attic': 1, 'attic': 1, 'rung': 1, 'brigade': 1, 'smashed': 1, 'sandy': 1, 'standard': 1, 'XTV': 1, '212': 1, 'Yard': 1, 'Whitehall': 1, '1212': 1, 'rotten': 1, 'Sullivans': 1, 'stinks': 1, 'chairs': 1, 'trashy': 1, 'Sullivan': 1, 'wears': 1, 'somerset': 1, 'water-rat': 1, 'willow': 1, 'Hare': 1, 'kick': 1, 'beak': 1, 'Porky': 1, 'Paulkey': 1, 'threaten': 1, 'bleeding': 1, 'chimney': 1, 'seat': 1, 'douche': 1, 'Carr': 1, 'Gate': 1, 'T.': 1, 'holbrook': 1, 'Idea': 1, 'stupid': 1, 'clowns': 1, 'circus': 1, 'hoses': 1, 'pointing': 1, 'siren': 1, 'hammering': 1, 'metals': 1, 'band': 1, 'peep': 1, 'dancing': 1, 'sounds': 1, 'YOUNG': 1, \"dad's\": 1, '22': 1, 'person': 1, 'E.G.': 1, 'younger': 1, 'stole': 1, 'truncheon': 1, 'almighty': 1, 'thud': 1, 'Jordan': 1, 'fighting': 1, 'grown': 1, 'understand': 1, 'nevertheless': 1, 'sunday': 1, 'older': 1, 'sank': 1, 'saved': 1, 'above': 1, 'raced': 1, 'hell': 1, 'pulling': 1, 'destroyed': 1, 'baths': 1, 'allowed': 1, 'programmes': 1, 'suitable': 1, 'digging': 1, 'unfit': 1, 'killing': 1, 'stabbed': 1, 'heads': 1, 'boasting': 1, 'fair': 1, 'machinery': 1, 'Some': 1, 'lowest': 1, 'hardest': 1, 'employment': 1, 'stuffy': 1, 'adding': 1, 'numbers': 1, 'Give': 1, 'stockman': 1, 'apprenticeship': 1, 'easter': 1, 'classes': 1, 'learn': 1, 'useful': 1, 'chap': 1, 'While': 1, 'shillings': 1, 'less': 1, 'worker': 1, 'Apprenticeship': 1, '%': 1, 'average': 1, 'chosen': 1, 'future': 1, 'career': 1, 'interested': 1, 'worked': 1, 'tips': 1, 'choose': 1, 'FARMING': 1, 'BARLEY': 1, '81': 1, 'Rose': 1, 'bored': 1, 'Mind': 1, 'Best': 1, 'Wishes': 1, 'teach': 1, 'Have': 1, 'marked': 1, 'Exams': 1, 'papers': 1, 'cheer': 1, 'class': 1, 'flu': 1, 'Barley': 1, '3C': 1, 'eight': 1, 'Coote': 1, 'college': 1, 'Handsome': 1, 'bookbinding': 1, 'steady': 1, 'binding': 1, 'hates': 1, 'gown': 1, 'carry': 1, 'prayer-book': 1, 'pageboy': 1, 'dress': 1, 'ride': 1, 'Touring': 1, 'Sat': 1, 'fence': 1, 'dense': 1, 'TWO': 1, 'PEOPLE': 1, 'CHARACTERS': 1, 'SCENE': 1, 'teenager': 1, 'asks': 1, 'date': 1, \"O'clock\": 1, 'seagull': 1, 'mucking': 1, 'winter': 1, 'boring': 1, \"Whoever's\": 1, \"whoever's\": 1, 'ends': 1, '10.30': 1, 'cheerio': 1, 'supper': 1, 'Motorbike': 1, 'beautiful': 1, 'Glad': 1, 'Meet': 1, 'Married': 1, 'special': 1, 'March': 1, '4th': 1, 'Dec': 1, '25th': 1, 'Christmas': 1, 'steps': 1, 'photos': 1, 'Congratulations': 1, 'Thank': 1, 'Pop': 1, 'pop': 1, 'singers': 1, 'Wryer': 1, 'Falling': 1, \"Adam's\": 1, 'group': 1, 'Beverly': 1, 'Everly': 1, 'Brothers': 1, 'painted': 1, 'olden': 1, 'raining': 1, 'licking': 1, 'cage': 1, 'happening': 1, 'fashioned': 1, \"grandpa's\": 1, 'pants': 1, 'Pram': 1, 'weekly': 1, 'changed': 1, \"Baker's\": 1, 'knock': 1, 'Miss': 1, 'kettle': 1, 'finding': 1, 'shared': 1, 'altar': 1, 'knees': 1, 'tins': 1, 'JUST': 1, 'MARRIED': 1, 'lipstick': 1, 'clearing': 1, 'themselves': 1, 'bonny': 1, 'fond': 1, 'grew': 1, 'families': 1, 'WILLIAM': 1, 'GLEBE': 1, '90': 1, 'AN': 1, 'APPLE': 1, 'pinching': 1, 'especially': 1, 'careful': 1, 'wasps': 1, 'bump': 1, 'stings': 1, 'barbed': 1, 'wire': 1, 'probably': 1, 'unhook': 1, 'catches': 1, 'warn': 1, 'resist': 1, 'jacket': 1, 'recognized': 1, 'shows': 1, 'Fox': 1, 'beast': 1, 'sits': 1, 'cleaning': 1, 'savage': 1, 'chickens': 1, 'passing': 1, 'leap': 1, 'Chickens': 1, 'cackle': 1, 'collects': 1, 'WINTER': 1, 'robins': 1, 'seek': 1, 'crumbs': 1, 'numb': 1, 'Stranded': 1, 'Desert': 1, 'Island': 1, 'midsummer': 1, '9.30': 1, 'a.m.': 1, 'wrecked': 1, 'coral': 1, 'reef': 1, 'overboard': 1, 'sinking': 1, 'Getting': 1, 'impossible': 1, 'outfits': 1, 'volunteered': 1, 'shipwreck': 1, 'breath': 1, 'below': 1, 'gushed': 1, 'quickly': 1, 'crows': 1, 'Lucky': 1, 'tinned': 1, 'lifeboat': 1, 'trough': 1, 'agreed': 1, 'protested': 1, 'usually': 1, 'snake': 1, 'shortened': 1, 'coast': 1, 'several': 1, 'ships': 1, 'waving': 1, 'september': 1, 'short': 1, 'drank': 1, 'hunting': 1, 'drained': 1, 'tigers': 1, 'traps': 1, 'sticks': 1, 'slept': 1, 'coconut': 1, 'somebody': 1, 'december': 1, 'delighted': 1, 'shipwrecked': 1, 'WALTER': 1, 'PERKINS': 1, '94': 1, 'Small': 1, 'WE': 1, 'SIT': 1, 'GARDEN': 1, 'AND': 1, 'LAY': 1, 'PARK': 1, 'Cheetah': 1, 'prowls': 1, 'thick': 1, 'undergrowth': 1, 'Birds': 1, 'clatter': 1, 'escape': 1, 'Monkeys': 1, 'lions': 1, 'gathering': 1, 'roars': 1, 'prey': 1, 'Hong_Kong': 1, '32': 1, 'queer': 1, 'fore': 1, 'entered': 1, 'equipment': 1, 'Not': 1, 'Outside': 1, 'sirens': 1, 'ROGER': 1, 'SCOTT': 1, '97': 1, 'teachers': 1, 'Bicycle': 1, 'do_not': 1, 'Concreteville': 1, 'firm': 1, 'clout': 1, 'Italian': 1, 'Bat': 1, 'branches': 1, 'caves': 1, 'Bats': 1, 'flies': 1, 'sexton': 1, 'sows': 1, 'mouth': 1, 'sore': 1, 'area': 1, 'outbreak': 1, 'markets': 1, 'selling': 1, 'for_the': 1, \"Castle's\": 1, 'land': 1, 'building': 1, 'firms': 1, 'billed': 1, 'retire': 1, 'main': 1, 'Gut': 1, 'Roger': 1, 'Scott': 1, 'Bullocks': 1, 'hang': 1, 'pluck': 1, 'hook': 1, 'Day': 1, 'JAMES': 1, 'CARR': 1, '101': 1, 'Little': 1, 'Girl': 1, 'prostitute': 1, 'seeing': 1, '70': 1, 'pm': 1, 'common': 1, 'Durex': 1, 'intercourse': 1, 'discovered': 1, 'Smoking': 1, 'puff': 1, 'literature': 1, 'listening': 1, 'creak': 1, 'indiscreet': 1, 'bloody': 1, 'Nose': 1, 'Walk': 1, 'simple': 1, 'ABC': 1, 'Crazy': 1, 'mixed': 1, 'nutshell': 1, \"author's\": 1, 'tongue': 1, 'skilfully': 1, 'creeps': 1, 'muscles': 1, 'tense': 1, 'squeak': 1, \"cat's\": 1, 'claws': 1, 'curled': 1, 'Way': 1, 'Youth': 1, 'Probation': 1, 'oranges': 1, 'Covent': 1, 'Garden': 1, 'friendly': 1, 'Prison': 1, 'housebreaking': 1, 'pickpocketing': 1, 'keys': 1, 'Place': 1, 'driven': 1, 'seemed': 1, 'whiskey': 1, 'quiet': 1, 'By': 1, 'half_past': 1, 'Meanwhile': 1, 'position': 1, '100': 1, 'interned': 1, 'wad': 1, 'notes': 1, 'dropped': 1, 'bent': 1, 'realized': 1, 'drove': 1, 'trail': 1, 'windows': 1, 'robbery': 1, 'lump': 1, 'freezing': 1, 'icicles': 1, 'gutter': 1, 'crisp': 1, 'farmhouse': 1, 'far': 1, 'ditch': 1, 'towards': 1, 'locker': 1, 'ache': 1, 'delight': 1, 'bale': 1, 'strikes': 1, 'diesel': 1, 'loft': 1, 'Stop': 1, 'thief': 1, 'JACK': 1, \"O'MALLEY\": 1, '106': 1, 'Oldest': 1, 'Dilys': 1, 'keeps': 1, 'DIED': 1, 'SLOWLY': 1, 'mary': 1, 'injuries': 1, 'morphine': 1, 'RUNAWAY': 1, 'BOY': 1, 'trigger': 1, 'jogged': 1, 'stomach': 1, 'KILLER': 1, 'Greece': 1, 'iron': 1, 'candlestick': 1, 'SON': 1, 'WHO': 1, 'SHOT': 1, 'HIS': 1, 'FATHER': 1, '1949': 1, 'aged': 1, 'cupboard': 1, 'pointed': 1, 'neighbour': 1, 'DIMMOX': 1, 'wiped': 1, 'bending': 1, 'stick': 1, \"I've\": 1, 'SUDDEN': 1, 'buy': 1, 'yankee': 1, 'fixed': 1, 'darling': 1, 'ton': 1, 'ninety': 1, 'steering': 1, 'bang': 1, 'burned': 1, 'crash': 1, 'buried': 1, \"parent's\": 1, 'coffins': 1, 'heartbreak': 1, \"Jane's\": 1, 'unable': 1, 'attend': 1, 'joke': 1, 'loneliest': 1, 'Italy': 1, 'law': 1, 'TOM': 1, 'SULLIVAN': 1, '111': 1, 'Eight': 1, 'Janet': 1, 'Edna': 1, 'Three': 1, 'Terry': 1, 'Stuart': 1, 'Geoff': 1, 'blamed': 1, 'shoulder': 1, 'LEAVING': 1, 'SCHOOL': 1, 'pumps': 1, \"Sturgess's\": 1, 'Mording': 1, 'attached': 1, 'bullock': 1, 'heifer': 1, 'FARM': 1, 'unload': 1, 'dung': 1, 'uncovered': 1, 'mangels': 1, '11.30': 1, 'stuck': 1, 'bricks': 1, 'wheels': 1, 'warm': 1, 'T.V.O.': 1, 'low': 1, 'geared': 1, 'gears': 1, 'reverse': 1, 'cylinders': 1, 'hydraulic': 1, 'lift': 1, 'manifold': 1, 'burnt': 1, 'smoke': 1, 'sparks': 1, 'fill': 1, 'radiator': 1, 'sixpence': 1, 'Last': 1, 'at_all': 1, 'grub': 1, 'showed': 1, 'bill': 1, 'thanks': 1, '24th': 1, 'Bull': 1, \"Jones's\": 1, 'workmen': 1, 'Joe': 1, 'shed': 1, 'daisy': 1, 'thinks': 1, 'Toogey': 1, 'study': 1, 'sulk': 1, 'Fighting': 1, 'shadow': 1, 'geese': 1, 'drip': 1, 'feathers': 1, 'grieve': 1, 'goose': 1, 'Poor': 1, 'accident': 1, 'lad': 1, 'forget': 1, 'covered': 1, 'bob': 1, 'lorries': 1, 'hurried': 1, 'ROSE': 1, 'JAMESON': 1, '117': 1, 'shy': 1, \"isn't_it\": 1, 'kissing': 1, 'cuddling': 1, 'lent': 1, 'feeling': 1, 'thieves': 1, 'drain': 1, 'Harrison': 1, 'fungus': 1, 'spur': 1, 'earwig': 1, 'flick': 1, 'dig': 1, 'taste': 1, 'juicy': 1, 'tingle': 1, 'Until': 1, 'wonderful': 1, 'dreams': 1, 'Sorry': 1, 'coats': 1, 'gloves': 1, 'games': 1, 'game': 1, 'Jennifer': 1, 'advise': 1, 'make-up': 1, 'teaches': 1, 'skin': 1, 'step': 1, 'trap': 1, 'broken': 1, 'free': 1, 'anther': 1, 'whether': 1, 'male': 1, 'female': 1, 'ones': 1, 'worms': 1, 'breadcrumbs': 1, 'nicely': 1, 'Holiday': 1, 'swimming': 1, 'frogspawn': 1, 'underneath': 1, 'tank': 1, 'fins': 1, 'moat': 1, 'lane': 1, 'otherwise': 1, 'tadpoles': 1, 'paint': 1, 'stream': 1, 'chew': 1, 'swirling': 1, 'neck': 1, 'gives': 1, 'refreshing': 1, 'staring': 1, 'stronger': 1, 'sleepy': 1, 'closed': 1, 'wicked': 1, 'snooty': 1, 'greedy': 1, 'selfish': 1, 'borrowed': 1, 'sailed': 1, 'sticking': 1, 'beware': 1, 'horrid': 1, 'nearer': 1, 'cloak': 1, 'hood': 1, 'mask': 1, 'spy': 1, 'hid': 1, 'rowed': 1, 'bubbles': 1, 'dive': 1, 'hidden': 1, 'rich': 1, 'richer': 1, \"month's\": 1, 'Switzerland': 1, \"needn't\": 1, 'booze': 1, 'great': 1, 'thunder': 1, 'lightning': 1, 'scared': 1, 'rock': 1, 'tipped': 1, 'drowned': 1, 'rumour': 1, 'explored': 1, 'towers': 1, 'spider': 1, 'crawling': 1, 'bravest': 1, 'dared': 1, 'stiff': 1, 'grated': 1, 'absolutely': 1, 'horrified': 1, 'nails': 1, 'pin': 1, 'shrivelled': 1, 'disturb': 1, 'souvenir': 1, 'memory': 1, 'Misses': 1, 'knows': 1, \"children's\": 1, 'Slad': 1, 'grocer': 1, 'fruit': 1, 'Clarke': 1, 'a_while': 1, 'Pillow': 1, 'unconscious': 1, 'miring': 1, 'reply': 1, 'phone': 1, 'Nicholls': 1, \"they'll\": 1, \"hadn't\": 1, 'everyone': 1, 'Redhanded': 1, 'morgan': 1, 'basket': 1, 'laundry': 1, 'whose': 1, 'safely': 1, 'KENNETH': 1, 'PRIME': 1, '137': 1, 'Beat': 1, '`': 1, \"'\": 1, 'Mac': 1, 'Plester': 1, 'HEART': 1, 'Doc': 1, 'H': 1, 'Brother': 1, 'Us': 1, 'housework': 1, 'Here': 1, 'Fat': 1, 'Thin': 1, \"Dog's\": 1, 'Sexy': 1, 'rude': 1, 'Kidneys': 1, 'kidneys': 1, 'mess': 1, 'vampire': 1, 'kidney': 1, 'marshland': 1, 'footprints': 1, 'swamp': 1, 'cruiser': 1, 'Put': 1, 'Radio': 1, 'Command': 1, 'disposal': 1, 'chain': 1, 'floated': 1, 'rifle': 1, 'horns': 1, 'arguing': 1, 'run_away': 1, 'Aunty': 1, 'uncle': 1, 'Southwold': 1, 'Fire': 1, 'Farmer': 1, 'passed': 1, 'Dance': 1, 'muffled': 1, 'explosion': 1, 'ROBERT': 1, 'SHIRE': 1, '147': 1, 'leaning': 1, 'against': 1, 'Grey': 1, '6.39': 1, 'blonde': 1, 'Blackpool': 1, 'eleven': 1, 'nine': 1, 'studios': 1, 'unexpected': 1, 'trip': 1, 'comfortable': 1, 'Deck': 1, 'due': 1, 'crapped': 1, 'aboard': 1, 'shift': 1, 'lifted': 1, 'scrub': 1, 'belted': 1, 'December': 1, '10th': 1, 'Rat': 1, 'rat': 1, 'creature': 1, 'digs': 1, 'tunnels': 1, 'chicken': 1, 'hut': 1, 'wheat': 1, 'squeezes': 1, 'tiny': 1, 'cracks': 1, 'Mouse': 1, 'amongst': 1, 'pile': 1, 'heaps': 1, 'jumps': 1, 'With': 1, 'Big': 1, 'resting': 1, 'fluffy': 1, 'dragging': 1, 'crafty': 1, 'barley': 1, 'Tramp': 1, 'sleeps': 1, 'grubby': 1, 'twopence': 1, 'bread': 1, 'Like': 1, 'GERALD': 1, 'GOODCHILD': 1, '151': 1, 'MY': 1, 'FAMILY': 1, 'WIGGLE': 1, 'Blue': 1, 'Pleased': 1, 'kids': 1, 'Reward': 1, 'snakes': 1, 'apes': 1, 'Husband': 1, 'john': 1, 'search': 1, 'sleeping': 1, 'jump': 1, 'machine': 1, 'earth': 1, 'HEADLESS': 1, 'BOdy': 1, 'midwinter': 1, 'screamed': 1, 'mental': 1, 'naked': 1, 'examined': 1, 'jack': 1, \"ripper's\": 1, 'prints': 1, 'ripper': 1, 'charged': 1, '1897': 1, 'Work': 1, 'Stanley': 1, 'drives': 1, 'meats': 1, 'frying': 1, 'stewing': 1, 'Pudding': 1, 'beef': 1, 'kid': 1, 'pork': 1, 'hefty': 1, 'abattoir': 1, 'colt': 1, 'Leader': 1, 'bluestreak': 1, 'push-bicycle': 1, 'THursday': 1, 'JUDITH': 1, 'WARD': 1, '157': 1, 'attractive': 1, 'Cafe': 1, 'goodness': 1, 'glum': 1, 'Hall': 1, 'drinks': 1, 'Drink': 1, '1962': 1, 'least': 1, 'taller': 1, 'plays': 1, 'nursing': 1, 'part-time': 1, 'abroad': 1, \"Butlin's\": 1, 'Trevor': 1, 'send': 1, 'postcards': 1, 'remember': 1, 'notices': 1, 'nobody': 1, 'adopt': 1, \"days'\": 1, 'decide': 1, 'SUMMER': 1, 'HOLIDAYS': 1, 'beetroot': 1, 'Picked': 1, 'Betty': 1, 'groceries': 1, 'lb': 1, 'beans': 1, '2lb': 1, 'ham': 1, 'peaches': 1, 'cream': 1, '10d': 1, 'deeper': 1, 'shining': 1, 'glittering': 1, 'ahead': 1, 'waves': 1, \"It's\": 1, 'Where': 1, 'whispering': 1, 'French': 1, 'MUM': 1, \"j'aime\": 1, 'monsieur': 1, 'senor': 1, 'private': 1, 'secretary': 1, 'country': 1, 'huge': 1, 'rooms': 1, 'maids': 1, 'eldest': 1, 'known': 1, 'dressing': 1, 'crockery': 1, 'lots': 1, 'packed': 1, 'sunny': 1, 'early': 1, 'platform': 1, 'No': 1, 'pass': 1, 'registry': 1, 'celebrated': 1, \"Jenny's\": 1, 'doorbell': 1, 'couple': 1, 'Down': 1, 'Sunbathing': 1, 'Teena': 1, 'proposes': 1, 'Les': 1, 'O.K.': 1, 'lines': 1, 'lesson': 1, 'poems': 1, 'wishes': 1, 'PAT': 1, 'JOHNSON': 1, '167': 1, 'cowboy': 1, 'indian': 1, 'pens': 1, 'Denis': 1, 'Alec': 1, 'Keith': 1, 'See': 1, 'Phillis': 1, 'Eastwood': 1, 'horse': 1, 'Maverick': 1, 'Lone': 1, 'Ranger': 1, 'knit': 1, 'almost': 1, 'Thinking': 1, 'Cambridge': 1, \"King'\": 1, 'product': 1, 'plans': 1, 'conceived': 1, 'successively': 1, 'Revolt': 1, 'hungary': 1, 'communism': 1, 'blazed': 1, 'sooner': 1, 'communist': 1, 'countries': 1, 'follow': 1, 'ancestors': 1, 'stimulated': 1, 'unwisely': 1, 'advertisement': 1, 'display': 1, 'armed': 1, 'doctrine': 1, 'Yet': 1, 'control': 1, 'principle': 1, 'civilization': 1, 'pump': 1, 'wheel': 1, 'pie': 1, 'Huntigdon': 1, 'P': 1, 'speaking': 1, 'tie': 1, 'blouse': 1, 'grey': 1, 'cardigan': 1, '`I': 1, 'Fuller': 1, 'Ty': 1, 'Hardin': 1, 'Frankie': 1, 'Vaughan': 1, \"Walker'\": 1, 'encouraged': 1, 'minor': 1, 'role': 1, 'Kookie': 1, 'series': 1, 'Sunset': 1, 'Strip': 1, 'harm': 1, 'Edd': 1, 'Byrnes': 1, 'enjoys': 1, 'sports': 1, 'slightest': 1, 'desire': 1, 'possess': 1, 'ooo': 1, 'rod': 1, 'vernacular': 1, 'word': 1, 'Luck': 1, 'logs': 1, 'Cover': 1, 'protecting': 1, 'plants': 1, 'illustrate': 1, 'Baby': 1, 'begin': 1, 'shout': 1, 'Roof': 1, 'bath': 1, 'DAPHNE': 1, 'BADLAND': 1, '173': 1, 'Blind': 1, 'Television': 1, 'watson': 1, 'nanny': 1, 'mass': 1, 'Holy': 1, 'obligation': 1, 'untied': 1, 'anyway': 1, 'Lyons': 1, 'Every': 1, 'Bake-house': 1, 'sneezes': 1, 'birthday': 1, 'pink': 1, 'high': 1, 'heels': 1, 'wear': 1, 'valley': 1, 'Margaret': 1, 'calls': 1, 'loved': 1, 'ice': 1, 'sugar': 1, \"there'll\": 1, 'Persevere': 1, 'Doctor': 1, 'Wednesday': 1, 'Morning': 1, 'Our': 1, 'Toby': 1, 'Excited': 1, 'cute': 1, 'single': 1, \"haven't\": 1, 'round_about': 1, 'leaving': 1, 'Relatons': 1, 'Leiston': 1, 'puts': 1, 'paw': 1, 'meeting': 1, 'finish': 1, 'fun': 1, 'Went': 1, 'bikes': 1, 'Layne': 1, 'guided': 1, 'Deadline-midnight': 1, 'programme': 1, 'peeped': 1, 'Auutie': 1, 'Rosemary': 1, 'lonely': 1, 'miserable': 1, 'poor': 1, 'fine': 1, 'waiter': 1, 'Roast': 1, 'Potatoes': 1, 'Carrots': 1, 'chops': 1, 'enjoying': 1, \"aren't\": 1, 'indeed': 1, 'afterwards': 1, 'steam': 1, 'pudding': 1, 'point': 1, 'pet': 1, 'Jessamine': 1, 'High': 1, 'Street': 1, 'Maureen': 1, 'Pat': 1, 'MICHAEL': 1, 'HOLMES': 1, '180': 1, 'Heavens': 1, 'sighed': 1, 'mamma': 1, 'Babies': 1, 'weep': 1, 'heavens': 1, 'moon': 1, 'stars': 1, 'COMMENTARY': 1, 'spring': 1, 'May': 1, 'blossom': 1, 'July': 1, 'ripe': 1, 'fields': 1, 'reap': 1, 'September': 1, 'October': 1, 'busy': 1, 'ploughing': 1, 'Waesel': 1, 'aimed': 1, 'pinned': 1, 't': 1, 'knowing': 1, 'spell': 1, 'speller': 1, '3c': 1, '40': 1, 'practise': 1, 'difficulty': 1, 'neatly': 1, 'essential': 1, 'term': 1, 'spelling': 1, 'William': 1, 'Glebe': 1, 'concentrate': 1, 'listen': 1, 'important': 1, 'punctuation': 1, 'Yours': 1, 'faithfully': 1, 'pages': 1, 'plenty': 1, 'these': 1, 'form': 1, 'magazine': 1, 'Holmes': 1, 'Ben': 1, 'aunt': 1, 'Sue': 1, 'Kim': 1, 'be_coming': 1, 'Sally': 1, 'heat': 1, \"girlfriend's\": 1, 'Name': 1, 'Howlet': 1, 'maths': 1})\n"]},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for /: 'NoneType' and 'int'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-4-e2a55567c1b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-4-e2a55567c1b7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'me'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'me'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-4-e2a55567c1b7>\u001b[0m in \u001b[0;36mprob\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mtrain_tokenize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mProb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mProb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"]}]},{"cell_type":"markdown","metadata":{"id":"w8r8QYj78GPK"},"source":["## **Task 3** (15 Marks): \n","[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"]},{"cell_type":"code","metadata":{"id":"SV9Mu8P38IQE","executionInfo":{"status":"ok","timestamp":1536070558621,"user_tz":-60,"elapsed":956,"user":{"displayName":"John McCrae","photoUrl":"//lh3.googleusercontent.com/-whXIBV_wL0Y/AAAAAAAAAAI/AAAAAAAAATE/-2hfaPZsyHM/s50-c-k-no/photo.jpg","userId":"102173405218988557336"}},"outputId":"9f29e22b-0f8b-4b92-9d5f-fcde3efec970","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from nltk.metrics.distance import edit_distance\n","\n","# Edit distance returns the number of changes to transform one word to another\n","print(edit_distance(\"hello\", \"hi\"))"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hm46Lbiz8K8M"},"source":["Write a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n","\n","1. Collect the set of all unique tokens in `train`\n","2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n","3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n","\n","*Do not implement edit distance, use the built-in NLTK function `edit_distance`*"]},{"cell_type":"code","metadata":{"id":"HoilAmFW8PCb","tags":[]},"source":["\n","def get_candidates(token):\n","    train_tokenize = seperation()\n","    unique = set(train_tokenize) #gets unique words from the sentences\n","    dis=[]\n","    for i in unique:\n","        dis.append([edit_distance(i,token)])\n","        # calculates the distance for each token for the words in  training \n","\n","    distance = dict(zip(unique,dis))# stores the words and its distance\n","    sorted_dict = {k: v for k, v in sorted(distance.items(), key=lambda item: item[1])}\n","    values = min(sorted_dict.values())\n","    result = [key for key in sorted_dict if sorted_dict[key]==values]\n","    return result  # gets the words with same distance value\n","get_candidates('minde')\n","        \n","# Test your code as follows\n","#assert get_candidates(\"minde\") == ['mind', 'mine']"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['mind', 'mine']"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"RGY-eCkN8TIM"},"source":["## Task 4 (15 Marks):\n","\n","Write a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *unigram probability*. \n","\n","*Your solution to this should involve `get_candidates`*\n"]},{"cell_type":"code","metadata":{"id":"dIGKE4_P8WGP"},"source":["def correct(sentence):\n","    corrected = []\n","    similar =[]\n","   \n","    for i in sentence:\n","        similar.append(get_candidates(i)) #getting the values with similar edit distances\n","    #this loop calculates the highest probability between the same values  and returns the word\n","    for j in similar:\n","        if len(j)!=1:\n","            for i in j:\n","                low = {}\n","                low[i] = prob(i)\n","            values = max(low.values())\n","            result = [key for key in low if low[key]==values]\n","            corrected.extend(result)\n","        else:\n","            corrected.extend(j)\n","     \n","    return corrected\n","correct([\"this\",\"whitr\",\"cat\"])\n","\n","#assert(correct([\"this\",\"whitr\",\"cat\"]) = ['this','white','cat'])   "],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['this', 'white', 'cat']"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"oG7jC6au8kka"},"source":["## **Task 5** (10 Marks): \n","Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."]},{"cell_type":"code","metadata":{"id":"HSXTQypR8mdR","executionInfo":{"status":"ok","timestamp":1536071822989,"user_tz":-60,"elapsed":539,"user":{"displayName":"John McCrae","photoUrl":"//lh3.googleusercontent.com/-whXIBV_wL0Y/AAAAAAAAAAI/AAAAAAAAATE/-2hfaPZsyHM/s50-c-k-no/photo.jpg","userId":"102173405218988557336"}},"outputId":"853813e4-d71b-42a7-8e96-68d038457628","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from difflib import SequenceMatcher # returns the ratio of similarity\n","def accuracy():\n","    test = data[:100]\n","    algo = []\n","    acc = []\n","    test_corrected = [i['corrected'] for i in test]\n","    test_original = [i['original'] for i in test]\n","    # this loop calculates the accuracy of the algorithm.\n","    for i in range(0,len(test_original)):\n","        algo.append(correct(test_original[i]))\n","        acc.append(SequenceMatcher(None,test_corrected[i],algo[i]).ratio())\n","    total_accuracy = ((sum(acc)/len(acc))*100)\n","    return total_accuracy\n","accuracy()\n"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["79.26613818518715"]},"metadata":{},"execution_count":6}]},{"source":["## **Task 6 (35 Marks):**\n","\n","Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n","\n","* You may resources beyond those provided here.\n","* You must **not use the test data** in this task.\n","* Provide a short text describing what you intend to do and why. \n","* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n","* Your implementation should not consist of more than 50 lines of code\n","\n","Please note this task is marked according to: demonstration of knowledge from the lectures (10), originality and appropriateness of solution (10), completeness of description (10) and technical correctness (5)\n"],"cell_type":"markdown","metadata":{"id":"9b-r2JzD8_Zh"}},{"source":["## Solution\n","\n","### Consider the following example for first three solutions:\n","    ['NIGEL','THRUSH', 'February', '48'] -->  ['JILL', 'JUST', 'Bernard', '40']\n","1. Named Entitiy - (Implemented)\n","    In the algorithm the named entities such as names and organizational names were also condidered as a part of change which was not to be implemented like that, ex- 'NIGEL' was coverted to 'JILL'  So all named entity should be handled correctly and not changed.\n","\n","2. Numerical Data -(Implemented)\n","    The numerical data was also changed so this should also be handled.ex - 48 was changed to 40which was inappropriate\n","\n","3. Dates - \n","    For months like 'February' it was changed to 'Bernard' so this should be handled properly.\n","\n","4. Increase in DataSet - \n","    The training data was very less if it would have beem more exhaustive then it might have added the training list ,for correction in turn giving more accuracy.\n","\n","5. Morphology - \n","    There may be cases where the word is not in its reduced form so we can use stemming and lemmatization of such words, basically to have normalized corpus.\n","\n","6. Smoothing - \n","    We can use Language Model Smoothing to reduce zero probabilities\n","\n","7. Additional Methods - \n","    We can further implement Hidden Markov Models to increase accuracy, it will prove to be robust parser in this case.  (\n","    "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","from nltk import pos_tag\n","def correct_tag(sentence):\n","    corrected = []\n","    similar =[]\n","\n","    tags = ['NNP','CD']\n","    pos = pos_tag(sentence)  # pos tagging   \n","\n","   \n","    for i in pos:\n","        if i[1] in tags:\n","            similar.append([i[0]])# checking for proper noun and integers\n","        else:\n","            similar.append(get_candidates(i[0])) #getting the values with similar edit distances\n","    #this loop calculates the highest probability between the same values  and returns the word\n","    for j in similar:\n","        if len(j)!=1:\n","            for i in j:\n","                low = {}\n","                low[i] = prob(i)\n","            values = max(low.values())\n","            result = [key for key in low if low[key]==values]\n","            corrected.extend(result)\n","        else:\n","            corrected.extend(j)\n","     \n","    return corrected"]},{"source":["## **Task 7 (5 Marks):**\n","\n","Repeat the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4"],"cell_type":"markdown","metadata":{"id":"GLzaC6D28sK9"}},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["87.18168894442178"]},"metadata":{},"execution_count":52}],"source":["from difflib import SequenceMatcher # returns the ratio of similarity\n","def accuracy():\n","    test = data[:100]\n","    algo = []\n","    acc = []\n","    test_corrected = [i['corrected'] for i in test]\n","    test_original = [i['original'] for i in test]\n","    # this loop calculates the accuracy of the algorithm.\n","    for i in range(0,len(test_original)):\n","        algo.append(correct_tag(test_original[i]))\n","        acc.append(SequenceMatcher(None,test_corrected[i],algo[i]).ratio())\n","    total_accuracy = ((sum(acc)/len(acc))*100)\n","    return total_accuracy\n","accuracy()"]},{"source":["We can see that in previous implementation we were getting 79 % accuracy but after handling of the proper nouns and integer values there was a significant chnage in the accuracy, it increased by almost 8 percent going to 87 %."],"cell_type":"markdown","metadata":{}}]}