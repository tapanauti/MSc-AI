{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "name": "Exercise Sheet 3 - VSM - Solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M_v-BtFh0dr"
      },
      "source": [
        "# Exercise Sheet 3 - Vector Space Models and Word Embeddings - Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_op0C-mNsyIN"
      },
      "source": [
        "# Learning Objectives\n",
        "    - Introduction to word vectors\n",
        "    - Overview on distributional semantics\n",
        "--------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26KdXQvBtyrG"
      },
      "source": [
        "# setting the stage ;)\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMJATpKsyIO"
      },
      "source": [
        "# Preprocessing: Tokenization & POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvxlx6dsyIO",
        "outputId": "306b570f-22de-42ef-8954-2bd1c64ea93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Sentence tokenization with nltk\n",
        "import nltk\n",
        "\n",
        "sentence = \"The quick brown fox jump|jumps over the lazy dog.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jump|jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UpaRe6KsyIU",
        "outputId": "b07c0e51-31ac-4f0c-dc0f-75cdaea9b18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Part-of-Speech (POS) Tagging\n",
        "\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jump|jumps', 'NNS'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0fDIB2xsyIl"
      },
      "source": [
        "### Exercise 1: How to get rid of the punctuations from the text?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaN6BGKyXAjt",
        "outputId": "2509c71e-2f2d-449f-e68d-ab6fbd7e19a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import string\n",
        "\n",
        "text = \"Remember, remember, the fifth of November, Gunpowder, treason and plot! If you can't give us one, we'll take two; The better for us and the worse for you!\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Your code goes here\n",
        "refined_tokens = [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "print(refined_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Remember', 'remember', 'the', 'fifth', 'of', 'November', 'Gunpowder', 'treason', 'and', 'plot', 'If', 'you', 'ca', \"n't\", 'give', 'us', 'one', 'we', \"'ll\", 'take', 'two', 'The', 'better', 'for', 'us', 'and', 'the', 'worse', 'for', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGL290idYD3_"
      },
      "source": [
        "Hint: a list of punctuations could be used (Check string.punctuation on https://docs.python.org/3/library/string.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLWR4i0QsyIu"
      },
      "source": [
        "----\n",
        "# Distributional Semantics & Word Vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S3oEARDELAI"
      },
      "source": [
        "## Context Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V50m3t7uDM83"
      },
      "source": [
        "### Exercise 2: looks up every occurrence of the word \"affection\" and prints out it's context in the text of Sense and Sensibility by Jane Austen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUen6tsGEP9y"
      },
      "source": [
        "# Import books from nltk for further processing\n",
        "from nltk.book import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0pRrdWjEaR6",
        "outputId": "db734075-e0bd-441d-da1c-52b742dc7d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Your code goes here\n",
        "text2.concordance(\"affection\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying 25 of 79 matches:\n",
            ", however , and , as a mark of his affection for the three girls , he left them\n",
            "t . It was very well known that no affection was ever supposed to exist between\n",
            "deration of politeness or maternal affection on the side of the former , the tw\n",
            "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
            "hich forbade the indulgence of his affection . She knew that his mother neither\n",
            "rd she gave one with still greater affection . Though her late conversation wit\n",
            " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
            "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
            ", and which recommended him to her affection beyond every thing else . His soci\n",
            "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
            " the most pointed assurance of her affection . Elinor could not be surprised at\n",
            "he natural consequence of a strong affection in a young and ardent mind . This \n",
            " opinion . But by an appeal to her affection for her mother , by representing t\n",
            " every alteration of a place which affection had established as perfect with hi\n",
            "e will always have one claim of my affection , which no other can possibly shar\n",
            "f the evening declared at once his affection and happiness . \" Shall we see you\n",
            "ause he took leave of us with less affection than his usual behaviour has shewn\n",
            "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
            "onths , without telling her of his affection ;-- that they should part without \n",
            "ould be the natural result of your affection for her . She used to be all unres\n",
            "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
            "th no inclination for expense , no affection for strangers , no profession , an\n",
            "till distinguished her by the same affection which once she had felt no doubt o\n",
            "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
            " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_xZItbMhe3X"
      },
      "source": [
        "Hint: We have already done that in Exercise Sheet 1.1 using NLTK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZxu2bapFIW_"
      },
      "source": [
        "## n-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Na5OI8LsyJC"
      },
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "text = \"You shall know a word by the company it keeps meaning - Firth (1957)\"\n",
        "tokenize = nltk.word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-t50lnDsyJF",
        "outputId": "45cd6c6b-0f66-48a6-c80f-ba4607ed5d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# show all possible n-grams\n",
        "bigrams = ngrams(tokenize,2)\n",
        "for b in bigrams:\n",
        "    print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('You', 'shall')\n",
            "('shall', 'know')\n",
            "('know', 'a')\n",
            "('a', 'word')\n",
            "('word', 'by')\n",
            "('by', 'the')\n",
            "('the', 'company')\n",
            "('company', 'it')\n",
            "('it', 'keeps')\n",
            "('keeps', 'meaning')\n",
            "('meaning', '-')\n",
            "('-', 'Firth')\n",
            "('Firth', '(')\n",
            "('(', '1957')\n",
            "('1957', ')')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDoXkyFQsyJI"
      },
      "source": [
        "### Frequency of occurence for each bigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axcfICx5syJK",
        "outputId": "6f6f2189-1a6c-4563-898f-9229b9276d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#### showing n-grams with raw frequency\n",
        "\n",
        "from nltk.collocations import *\n",
        "import nltk# for sent in tokens:\n",
        "#   refined_token = [token for token in sent if token not in string.punctuation]\n",
        "#You should tokenize your text\n",
        "text = \"The cat lies on the mat's and a dog! lies on the floor\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n",
        "bigrams = BigramCollocationFinder.from_words(tokens)\n",
        "for bigram, freq in bigrams.ngram_fd.items():  \n",
        "      print(bigram, freq)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cat', 'lies', 'on', 'the', 'mat', \"'s\", 'and', 'a', 'dog', '!', 'lies', 'on', 'the', 'floor']\n('The', 'cat') 1\n('cat', 'lies') 1\n('lies', 'on') 2\n('on', 'the') 2\n('the', 'mat') 1\n('mat', \"'s\") 1\n(\"'s\", 'and') 1\n('and', 'a') 1\n('a', 'dog') 1\n('dog', '!') 1\n('!', 'lies') 1\n('the', 'floor') 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G4v5hoJsyJP",
        "outputId": "ddb14abc-83e9-4d32-f092-c3dc2732cfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# show n-grams measured using Pointwise Mutual Information\n",
        "\n",
        "from nltk.collocations import *\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "\n",
        "#finder = BigramCollocationFinder.from_words(nltk.corpus.genesis.words('english-web.txt'))\n",
        "finder = BigramCollocationFinder.from_words(text1)\n",
        "\n",
        "finder.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',)', 'Star'),\n",
              " ('.--\"', 'Whose'),\n",
              " ('103', 'Measurement'),\n",
              " ('11', 'Nightgown'),\n",
              " ('12', 'Biographical'),\n",
              " ('29', 'Enter'),\n",
              " ('37', 'Sunset'),\n",
              " ('38', 'Dusk'),\n",
              " ('46', 'Surmises'),\n",
              " ('58', 'Brit')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ57fYl_syJR"
      },
      "source": [
        "... making PMI more interpretable, print out only n-grams which apear about a certain threshold "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L3mlQCGsyJR",
        "outputId": "fa483bc2-14aa-4643-be0c-20d41eeb7357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "freq_threshold = 30\n",
        "finder = BigramCollocationFinder.from_words(text1)\n",
        "finder.apply_freq_filter(freq_threshold)\n",
        "finder.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Moby', 'Dick'),\n",
              " ('Sperm', 'Whale'),\n",
              " ('White', 'Whale'),\n",
              " ('Right', 'Whale'),\n",
              " ('Captain', 'Peleg'),\n",
              " (',\"', 'said'),\n",
              " ('!\"', 'cried'),\n",
              " ('each', 'other'),\n",
              " (',\"', 'cried'),\n",
              " ('on', 'board')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MicxTCPasyJU"
      },
      "source": [
        "### Exercise 3: Interpret the variation in pmi based on frequency threshold?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znicrPcHf6Md",
        "outputId": "be3674ce-206a-4b3c-d9af-52235d8db10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Your code goes here\n",
        "freq_threshold = 100\n",
        "finder = BigramCollocationFinder.from_words(text1)\n",
        "finder.apply_freq_filter(freq_threshold)\n",
        "finder.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Sperm', 'Whale'),\n",
              " (',\"', 'said'),\n",
              " ('?\"', '\"'),\n",
              " ('have', 'been'),\n",
              " ('don', \"'\"),\n",
              " (\"'\", 'll'),\n",
              " (\"'\", 's'),\n",
              " ('at', 'last'),\n",
              " (\"'\", 't'),\n",
              " ('had', 'been')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v05j_B273EXl",
        "outputId": "146e9823-3734-4fb3-f36e-4eedff69906b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Your code goes here\n",
        "freq_threshold = 10\n",
        "finder = BigramCollocationFinder.from_words(text1)\n",
        "finder.apply_freq_filter(freq_threshold)\n",
        "finder.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.*', '*'),\n",
              " ('Cape', 'Horn'),\n",
              " ('New', 'Bedford'),\n",
              " ('Moby', 'Dick'),\n",
              " ('she', 'blows'),\n",
              " (\",'\", 'says'),\n",
              " (\".'\", '\"\\''),\n",
              " ('chief', 'mate'),\n",
              " ('years', 'ago'),\n",
              " ('lower', 'jaw')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rMfBL2G2sc6"
      },
      "source": [
        "Hint: Change frequency threshold to 100 and 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGsBiblqWpdG"
      },
      "source": [
        "*Please write your interpretation here*\n",
        "\n",
        "Frequency threshold is a limit below which all the co-occurrences are ignored. If we set it as 30, then all the bigram co-occurrences that lie below 30 are ignored. \n",
        "We can see if we go on either extreme i.e. 10 or 100, we tend to get the less important bigrams that may occur less frequently (10) or more frequency (100). \n",
        "This frequency threshold is a term frequency of a given bigram.\n",
        "Furthermore, you can read more about term frequency (tf) and inverse document frequency (idf). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz0TZdMTcsH-"
      },
      "source": [
        "## Pointwise Mutual Information (PMI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRrh1llsex_1",
        "outputId": "a9d204e0-9d17-41f5-9e15-b176d9046b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"eat sleep code repeat sleep dream code repeat\"\n",
        "\n",
        "Bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(word_tokenize(text))\n",
        "\n",
        "for i in finder.score_ngrams(Bigram_measures.pmi):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(('code', 'repeat'), 2.0)\n",
            "(('dream', 'code'), 2.0)\n",
            "(('eat', 'sleep'), 2.0)\n",
            "(('sleep', 'dream'), 2.0)\n",
            "(('repeat', 'sleep'), 1.0)\n",
            "(('sleep', 'code'), 1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaOnODVifDkG"
      },
      "source": [
        "### Exercise 4: What role does PMI may play in language modelling?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT_VkuAfgRUx"
      },
      "source": [
        "*Please write your answer here*\n",
        "\n",
        "If PMI of the given bigram is more then they are more likely to occur together in the wild. Hence, we can leverage this while assigning the conditional probability of a word based on its context (previous word). Likewise, the probability of the sentence can be calculated which is the multiplication of probabilities of each word in a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdBaoatsyJZ"
      },
      "source": [
        "\n",
        "# Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L__0nWIZsyJZ",
        "outputId": "ee42a244-bf04-40a8-edab-01c549f101a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# example of a sparse word vector\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        " \n",
        "corpus = [\n",
        "'All my cats in a row.',\n",
        "'When my cat sits down, she looks like a Furby toy!',\n",
        "'The cat from outer space',\n",
        "'Sunshine loves to sit like this for some reason.'\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "print(vectorizer.toarray())\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'CountVectorizer' object has no attribute 'toarray'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-d7a8a4e19c7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m ]\n\u001b[0;32m     11\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'toarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WrLXrZb4pr0"
      },
      "source": [
        "### Exercise 5: Write your intepretation of above vector representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJm03kGF9Jop"
      },
      "source": [
        "*Please write your answer here*\n",
        "\n",
        "It's a vector representation of each sentence based on the vocabulary in Corpus. Each column represents a word from the vocabulary and 1 indicates presence or absence of that word. \n",
        "E.g. Word \"cat\" has an index 1. As it is present in sentences 2 and 3, we can see value 1 at index 1 of both sentences.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzmlV3WVsyJb"
      },
      "source": [
        "## Word Co-occurrence Matrix in sparse CRS (Compressed Sparse Row) format\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBdNRjtDsyJb",
        "outputId": "eb532c4f-62b8-45bb-ef1e-7bb11ccb2865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "docs = ['the cat lies on the map',\n",
        "        'the cat lies on the floor',\n",
        "        'an cat sits near the floor']\n",
        "        \n",
        "# create your bag of words model using only unigrams\n",
        "count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
        "X = count_model.fit_transform(docs)\n",
        "\n",
        "# print the vocab & thier corrosponding index\n",
        "print(count_model.vocabulary_)\n",
        "\n",
        "# print the BOW\n",
        "print(X)\n",
        "\n",
        "# Co-occurance matrix calculation\n",
        "\n",
        "X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence if\n",
        "# you don't want co-occurrence that are spurious from the own text, set \n",
        "# occurrence that is greater that 1 to 1\n",
        "\n",
        "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
        "\n",
        "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
        "\n",
        "# print out matrix in dense format\n",
        "print(Xc.todense()) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 8, 'cat': 1, 'lies': 3, 'on': 6, 'map': 4, 'floor': 2, 'an': 0, 'sits': 7, 'near': 5}\n",
            "  (0, 8)\t2\n",
            "  (0, 1)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 4)\t1\n",
            "  (1, 8)\t2\n",
            "  (1, 1)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 2)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 5)\t1\n",
            "[[0 1 1 0 0 1 0 1 1]\n",
            " [1 0 2 2 1 1 2 1 3]\n",
            " [1 2 0 1 0 1 1 1 2]\n",
            " [0 2 1 0 1 0 2 0 2]\n",
            " [0 1 0 1 0 0 1 0 1]\n",
            " [1 1 1 0 0 0 0 1 1]\n",
            " [0 2 1 2 1 0 0 0 2]\n",
            " [1 1 1 0 0 1 0 0 1]\n",
            " [1 3 2 2 1 1 2 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG3kSJqCsyJf"
      },
      "source": [
        "### Exercise 6: Explain the matrix!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy4JB5y1ifNT"
      },
      "source": [
        "*Write your answer here*\n",
        "\n",
        "It’s a co-occurrence matrix, showing how words appear in the corpus (docs) given a specific context window. In this example unigrams are used (window of 1 word after and before). The word \"an\" index=0, and \"cat\" index=1 appeared once in the same context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwP5JerFsyJl"
      },
      "source": [
        "# Word2Vec\n",
        "\n",
        "Mikolov, Tomas; et al. \"Efficient Estimation of Word Representations in Vector Space\". arXiv:1301.3781\n",
        "\n",
        "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.[Wikipedia]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC77cEZwsyJo",
        "outputId": "ee79384b-58fc-47e6-94ea-85b455b148e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# gensim - open-source vector space modeling and topic modeling toolkit\n",
        "\n",
        "import gensim\n",
        "from nltk.corpus import brown\n",
        "model = gensim.models.Word2Vec(brown.sents())\n",
        "model.save('brown.embedding')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCn-mlETsyJq",
        "outputId": "fa42834c-1eb3-4019-ba62-ceafd65ee735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "new_model = gensim.models.Word2Vec.load('brown.embedding')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqa-VdVFsyJu",
        "outputId": "6cbb90ca-b373-4dad-bf46-c2eb7e768f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# word vector dimensionality\n",
        "\n",
        "len(new_model['university'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k66-_Z3VsyJx",
        "outputId": "47f14ee1-54ed-4e09-c896-f5bc6499fbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# show word similarity between words, calculated on the non-zero word vectors\n",
        "\n",
        "new_model.similarity('university','school')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84544945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-caXf8dsyJ0"
      },
      "source": [
        "### Exercise 7: Calculate and interpret the similarity between (bank, river) and (bank, deposit)? How will you handle word sense disambiguation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bFxvlPBsyJ1",
        "outputId": "009b43bc-7bc1-4c11-821d-5b58d4ac45a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Your code goes here\n",
        "print(new_model.similarity('bank','river'))\n",
        "print(new_model.similarity('bank','deposit'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.92647356\n",
            "0.8754487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsBoLdrspReJ"
      },
      "source": [
        "*Your answer goes here*\n",
        "\n",
        "Wordnet could be used to avoid ambiguity.Check http://wordnetweb.princeton.edu/perl/webwn?o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=&o3=&o4=&s=bank&i=0&h=000000000000000000#c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp3mhluasLgO",
        "outputId": "67e9f20e-27e6-4eda-885c-4c94a57d2ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# # download the Google newsW1v model from \n",
        "! wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\" # This may take a while depending upon your internet speed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-28 17:11:35--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.80.14\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.80.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.2MB/s    in 1m 48s  \n",
            "\n",
            "2020-09-28 17:13:24 (14.5 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fydqymFy5aen",
        "outputId": "1f245b9c-d1a8-4a82-9c39-1915091751a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount your drive to the colab notebook\n",
        "# To avoid multiple downloads, we mount the drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") #authorization is required here\n",
        "\n",
        "# If this does not work you may execute next cell"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI0xARyk17jN",
        "outputId": "43d9846a-db9d-4715-a992-5e6712bf535a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from nltk.data import find\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "# Uncomment this code if you are using drive mount\n",
        "# Mention path where GoogleNews-vectors-negative300.bin.gz file is downloaded (it should be on the same loacation where your colab notebook is)\n",
        "filename = '/content/drive/My Drive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz'\n",
        "\n",
        "## Uncomment if drive mount did not work for you\n",
        "# filename = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtL1KKXI163E",
        "outputId": "b91aece4-9674-4da1-d278-e67a3dc07b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of entries in the Word2Vec matrix\n",
        "\n",
        "len(model.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adh9rqHl16Hs",
        "outputId": "45cd4e5c-ae71-47a4-a2e6-de8ed23953f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dimensionality of of the dense word vectors\n",
        "\n",
        "len(model['university'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXPkB68psyKB",
        "outputId": "3926c3e0-afc4-4b92-f1e4-05964b20120e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# most similar words based on Word2Vec\n",
        "\n",
        "model.most_similar(positive=['soccer'], topn = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Soccer', 0.7622618675231934),\n",
              " ('football', 0.7313547730445862),\n",
              " ('basketball', 0.681098461151123),\n",
              " ('volleyball', 0.664727509021759),\n",
              " ('softball', 0.6443414688110352),\n",
              " ('lacrosse', 0.643805980682373),\n",
              " ('water_polo', 0.6297686100006104),\n",
              " ('hockey', 0.6270937919616699),\n",
              " ('tennis', 0.6163382530212402),\n",
              " ('futbol', 0.6026160717010498)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTqgcpnsyKH",
        "outputId": "bfea14e9-a42f-4f33-912b-401599aba797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# most dissimilar entry among provided words\n",
        "\n",
        "model.doesnt_match('wrestling cooking dinner potato'.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wrestling'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkIPGmXlsyKL"
      },
      "source": [
        "## Vector operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjThcGUPsyKM",
        "outputId": "503c4efc-1d58-4617-f795-7462af17becf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.most_similar(positive=['woman','king'], negative=['man'], topn = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT7SN3jrsyKO",
        "outputId": "7973a3e2-e428-427e-efaa-acc67cdaf800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.most_similar(positive=['Delhi','Russia'], negative=['Mosco'], topn = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('India', 0.6403084993362427)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXzCXSfYsyKP"
      },
      "source": [
        "### Excercise 8: Can you think of similar examples?\n",
        "\n",
        "Actor - male + female?\n",
        "\n",
        "batman - bat + spider?\n",
        "\n",
        "summer - sun + cold?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCUGMLUpNewy"
      },
      "source": [
        "*Guess the result here before executing the code*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLKf_Yh_syKR",
        "outputId": "e7a719e5-2d60-43cc-b6d1-0c8b8374e44a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Your code goes here\n",
        "print(model.most_similar(positive=['Actor','female'], negative=['male'], topn = 1))\n",
        "print(model.most_similar(positive=['batman','spider'], negative=['man'], topn = 1))\n",
        "print(model.most_similar(positive=['summer','cold'], negative=['sun'], topn = 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('Actress', 0.7435436844825745)]\n",
            "[('spiders', 0.5383533835411072)]\n",
            "[('winter', 0.5884253978729248)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNAd3mz_dnkZ"
      },
      "source": [
        "# Visualizing Vector Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1OBxo1Cdm5-",
        "outputId": "bcea86ba-14e9-4f98-c142-7aaf1395ae5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import numpy as np\n",
        "labels = []\n",
        "count = 0\n",
        "max_count = 50\n",
        "X = np.zeros(shape=(max_count,len(model['university'])))\n",
        "\n",
        "for term in model.vocab:\n",
        "    X[count] = model[term]\n",
        "    labels.append(term)\n",
        "    count+= 1\n",
        "    if count >= max_count: break\n",
        "\n",
        "# It is recommended to use PCA first to reduce to ~50 dimensions\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=50)\n",
        "X_50 = pca.fit_transform(X)\n",
        "\n",
        "# Using TSNE to further reduce to 2 dimensions\n",
        "from sklearn.manifold import TSNE\n",
        "model_tsne = TSNE(n_components=2, random_state=0)\n",
        "Y = model_tsne.fit_transform(X_50)\n",
        "\n",
        "# Show the scatter plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(Y[:,0], Y[:,1], 20)\n",
        "\n",
        "# Add labels\n",
        "for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
        "    plt.annotate(label, xy = (x,y), xytext = (0, 0), textcoords = 'offset points', size = 10)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVyU1f7A8c8DIqiomHLNrcA0xWEZBURElDS33BWzIhO9WqmpP0vTrmXL9XZNzEytzBVTXAqvyzWzVCRRMQEbDJdym1yuuaAoI4ss5/cHMA3DIiazwJz36+Ur5tnm+zTwnDnb9yhCCCRJkiTbY2fpACRJkiTLkAWAJEmSjZIFgCRJko2SBYAkSZKNkgWAJEmSjaph6QAqolGjRsLNzc3SYUiSJFUpSUlJN4QQrmXtrxIFgJubG4mJiZYOQ5IkqUpRFOX38vbLJiBJkiQbJQsASapkzzzzDGlpaQA4OzsDoNVq8fT0tGRYklRClWgCkqSqZOfOnZYOQZIqRNYAJOkBRUREsGjRIgCmTp1K9+7dAYiJiSEsLAw3Nzdu3LhhyRAlqUIeugBQFMVJUZQjiqIkK4pyXFGU9wu3uyuK8pOiKGcURdmkKErNwu2Oha/PFO53e9gYJMmcgoODiYuLAyAxMRGdTkdOTg5xcXF07drVwtFJUsVVRg0gG+guhPAB1EAfRVE6AR8BnwghWgG3gL8XHv934Fbh9k8Kj5OkKiFVl02Nvz1BQmIid+7cwdHRkcDAQBITE4mLiyM4ONjSIUpShT10H4AoSCeqK3zpUPhPAN2BFwq3rwHeA74ABhX+DBANLFEURREyLalk5bZpLjNj8zEc7Oy4Tn3emLOQzp074+3tzb59+zhz5gweHh6WDlOSKqxS+gAURbFXFEUDXAN2A2eBNCFEbuEhl4BmhT83Ay4CFO6/DTSsjDgkyVRSddnM2HyMrJx80rNzcWjWjsgvl6D270RwcDBLly6lffv2KIpi6VAlqcIqpQAQQuQJIdRAc6Aj0PZhr6koysuKoiQqipJ4/fr1h45Rkh7GpVuZONj9+efi2FxFru4mTZ/0oXHjxjg5OcnmH6nKqdRhoEKINEVR9gGBgIuiKDUKv+U3By4XHnYZaAFcUhSlBlAfSC3lWsuAZQB+fn6yeUiyqOYNapGTn69/XctNTZt//JfWzRoB8Ntvv+n3abVa/c86XUHrqJubGykpKeYJVpIqqDJGAbkqiuJS+HMtoCdwEtgHhBYeNgrYVvjz9sLXFO6Pke3/1U9eXp6lQ6hUDZ0dmTfMGycHO+o61sDJwY55w7xp6Oxo6dAk6S+rjBpAE2CNoij2FBQoXwshdiiKcgLYqCjKHOBnYGXh8SuBtYqinAFuAs9VQgxSJYqIiMDR0ZHJkyczdepUkpOTiYmJISYmhpUrVzJq1CjeffddsrOzeeKJJ1i9ejXOzs64ubkxYsQIdu/ezZtvvskjjzxS6nFV1UB1M4JaNeLSrUyaN6glH/5SlffQNQAhxDEhRHshhLcQwlMI8UHh9nNCiI5CiFZCiOFCiOzC7VmFr1sV7j/3sDFIlau8ce7e3t7MmTOHPXv2cPToUfz8/FiwYIH+3IYNG3L06FGefvrpco+rqho6O+LTwkU+/KVqQaaCkIopbZx7hw4d9OPcBw4cyIkTJwgKCgLg3r17BAYG6s8fMWIEAIcPHy73OEmSLE8WAJJeRca5u7u707NnTzZs2FDqNerUqQOAEKLc4yRJsjyZC0gCKj7OvVOnThw8eJAzZ84AcPfu3WIjYIpU9DhJkixHFgASUPFx7q6urkRGRvL888/j7e1NYGAgp06dKnG9ih4nSZLlKFVhBKafn5+QK4KZVqoum6CPYsjK+XOsu5ODHQdndJcdnpJURSmKkiSE8Ctrv6wBSIAc526LylqkZvbs2ezZs8cCEUnmJjuBJT05zl0C+OCDDywdgmQmsgYgFSPHuduWvLw8xo0bh0qlolevXmRmZhIeHk50dDQAM2fOpF27dnh7ezNt2jQLRytVNlkDkCQbdvr0aTZs2MDy5ct59tln2bx5s35famoqW7Zs4dSpUyiKol/nWKo+ZA1AkmyYu7s7arUaAF9f32KJ7OrXr4+TkxN///vf+c9//kPt2rUtFKVkKrIAkCQbk6rLJvliGrfuZuPo+GdTn729Pbm5ufrXNWrU4MiRI4SGhrJjxw769OljiXAlE5JNQJJkQwxne2fcvEJuVm6Zx+p0OjIyMnjmmWcICgqiZcuWZoxUMgdZAEiSjTCc7Z1FPrm5+Vy/k0WqLrvUTv/09HQGDRpEVlYWQohqkcxPKk4WAJJVul9K6nr16pGQkEBmZiahoaG8//77QMGole3bt1OjRg169erF/PnzLXwn1qNotncWBZP9atRvzJPjv+TSrUwaOjuWOsrnyJEj5g5TMiNZAEhWKTg4mI8//pjJkyeTmJhIdna2PiV1165dGT58OI888gh5eXn06NGDY8eO0axZMzlqpRzGq5oB5OTn07xBLQtFJFma7ASWrJKvry9JSUn6lNSBgYH6lNTBwcF8/fXXdOjQgfbt23P8+HFOnDghR63ch5ztLRmTNQDJqqTqsvUzkd3d3YmMjCyRkrpWrVrMnz+fhIQEGjRoQHh4OFlZWfpRK3v37iU6OpolS5YQExNj6VuyKnK2t2RIFgCS1TAcoZKTn0/71j7Mnz+fVatW4eXlxeuvv46vry937tyhTp061K9fn6tXr/Ldd98REhIiR61UUENnR/nglwBZAEhWwniECsABnSt/XLlCYGAgderU0aek9vHxoX379rRt25YWLVroVx2To1Yk6cHIAkCyCsYjVABcnujAjnPX9auMGS4oExkZWep15KgVSao42QksWQU5QkWSzE8WAJJVkCNUJMn8ZBOQZDXkCBVJMi9ZAEhWRY5QkSTzkU1AkiRJNkoWAJIkSTbqoQsARVFaKIqyT1GUE4qiHFcUZUrh9kcURdmtKMrpwv82KNyuKIqySFGUM4qiHFMUpcPDxiBJkiQ9uMqoAeQCbwgh2gGdgImKorQDZgJ7hRCtgb2FrwH6Aq0L/70MfFEJMUgPSavV4unpaekwpDLIz0cyhYcuAIQQV4QQRwt/TgdOAs2AQcCawsPWAIMLfx4EfCUKHAZcFEVp8rBxSJIkSQ+mUvsAFEVxA9oDPwGNhRBXCnf9ATQu/LkZcNHgtEuF24yv9bKiKImKoiRev369MsOUypCbm0tYWBgeHh6EhoaSkZFBUlIS3bp1w9fXl969e3PlSsFHevbsWfr06YOvry/BwcGcOnUKgPDwcCZPnkznzp1p2bIl0dHRlrylB2bN37Tz8vIYN24cKpWKXr16kZmZWebnIFkPrVZb5sx1ixNCVMo/wBlIAoYWvk4z2n+r8L87gC4G2/cCfuVd29fXV0imdf78eQGIAwcOCCGEGD16tJg3b54IDAwU165dE0IIsXHjRjF69GghhBDdu3cXv/32mxBCiMOHD4unnnpKCCHEqFGjRGhoqMjLyxPHjx8XTzzxhAXu5q87f/68UKlUlg6jhPPnzwt7e3vx888/CyGEGD58uFi7dm2Zn4NkHT7//HPRtm1b0bx5c9GtWzdx5coVs74/kCjKebZWyjwARVEcgM1AlBDiP4WbryqK0kQIcaWwieda4fbLQAuD05sXbpMsoCj9cv7d7GKJ1V588UU+/PBDUlJS6NmzJ1DwDbRJkybodDoOHTrE8OHD9dfJzs7W/zx48GDs7Oxo164dV69eNe8NVYKimtDRo0dRqVR89dVXnDx5ktdffx2dTkejRo2IjIykSRPTt1wafj7u7u6o1WqgYL0ErVZb7ucgWVZ6ejrvvvsuu3bt4tixY4SEhOjzWlmLhy4AFEVRgJXASSGEYfrF7cAoYG7hf7cZbH9NUZSNQABwW/zZVCSZkfEC4Vk5xXPx1K1bF5VKRXx8fLHtd+7cwcXFBY1GU+p1HR3/nMhV8CWkavn1119ZuXIlQUFBjBkzhs8++4wtW7awbds2XF1d2bRpE7NmzWLVqlUmjaPEAu7CXr/P3t6eq1evlvs5SJZRVGg3qJmPoijcvHkTADc3N8sGVorK6AMIAkYC3RVF0RT+e4aCB39PRVFOA08XvgbYCZwDzgDLgQmVEIP0gAzTL6dn55Kdm8/1Py6za++PAKxfv55OnTpx/fp1fQGQk5PD8ePHqVevHu7u7nzzzTdAwUM+OTnZYvdSGVJ12SRfTONWKTWh77//Xl8TUqvVzJkzh0uXLpk8HuPP54/CBdyLVMfPoarbprlM0EcxvLjiJ3ot+Ymxb83lrbfe4p133mHatGlkZGRYOsRiKmMU0AEhhCKE8BZCqAv/7RRCpAohegghWgshnhZC3Cw8XgghJgohnhBCeAkhEh/+NqQHVZR+2VDNhs1Z/NlneHh4cOvWLSZNmkR0dDQzZszAx8cHtVrNoUOHAIiKimLlypX4+PigUqnYtm1baW9TJRj+0YYujS+zJqTRaNBoNPzyyy/88MMPJo2ptM9HKdxuyNo+h86dOwMFHZ/r16+3aCzmZlxoZ+Xkszn1UZZFruPNN9/k+vXrfPzxx5YOsxiZC8hGGadfrlG/Me7jl/HVjO7FcvGo1Wr2799f4nx3d3d27dpVYrvxaAedTld5QZuA8UI0uQY1oT49uulrQsuXLyc+Pp7AwEBycnL47bffUKlUJourtM/H7ZUv9Omxp02bpt9X2udgKUVfEIoKgBdeeMHCEZmP8ZoW+fcyEZkZXLndjLp16+Lh4aFvDrIWMhWEjZLplws8bE3IVKrq5+Ps7AzAzJkziYuLQ61W88knn3D8+HE6duyIWq3G29ub06dPWzjSymdcaIv8PC7tWMSsSWN4//33+e6775gyZYoFIyxJqQqddH5+fiIxUbYUmYLhIuzW/nAxhVRdNkEfxRRr9nFysOOgUU3IUqra5+Ps7IxOpyM2Npb58+ezY8cOACZNmkSnTp0ICwvj3r175OXlUatW9VvsZ7vmMm8arGs9b5g33i45xMbGEh4ebvZ4FEVJEkL4lbVfNgHZOFtPv1z0Tdv4j9Za/p9Ulc+nqKAqS2BgIP/617+4dOkSQ4cOpXXr1maMznxKW9MiLS1NP3zX2sgCQLJ5ciGah1NsuOq9PLZrLlPP6JgXXniBgIAAvv32W5555hm+/PJLunfvbpF4Tc240HZxcbHaAkD2AUgW87BpF4ramytDQ2dHfFq4yIf/AzIe+QLw5uZj5Nk7kp6erj/u3LlztGzZksmTJzNo0CCOHTtmqZAlA7IGIEnSX2Y88gXAwc6O+s1aYW9vj4+PD+Hh4WRnZ7N27VocHBx49NFH+cc//mHBqKUisgCQLKoowdmhQ4do1qwZ27ZtY926dSxbtox79+7RqlUr1q5dS+3atTl//jwvvPACOp2OQYMGWTp0iZIjXx57PZqc/Hzc/1aPmJiYYsfOnDnT+HTJwmQTkGRRp0+fZuLEiRw/fhwXFxc2b97M0KFDSUhIIDk5GQ8PD1auXAnAlClTGD9+PL/88otZ8vBI91dVh6tKBWQNQDK7+yU4S0lJ4e233yYtLQ2dTkfv3r0BOHjwIJs3bwZg5MiRzJgxw2L3IP1JdqJXXbIAkMzqfgnOMjMzCQ8PZ+vWrfj4+BAZGUlsbKz+mILcg5K1qSrDVaXiZBOQZDYVSXAGBWl0mzRpQk5ODlFRUfrtQUFBbNy4EaDYdkmS/hpZAEhmU9EEZ//85z8JCAggKCiItm3b6rd/+umnfPbZZ3h5eXH5slxCQpIelkwFIZmNtaddkKTq5n6pIGQNQDIbOWJEkqyL7ASWzEqOGJEk6yELAMns5IgRSbIOsglIkiTJRskCQJIkyUbJAkCSJMlGyQJAkiqREIL8/Pz7HyhVCXl5eZYOwaRkAVAFpaWl8fnnnwMQGxtL//79H+j82bNns2fPHlOEZhMWLFiAp6cnnp6eLFy4EK1WS5s2bXjppZfw9PTk4sWLlg7RJs2ePZuFCxfqX8+aNYtPP/2UiIgI/P398fb25t1339XvHzx4ML6+vqhUKpYtW6bf7uzszBtvvIGPjw/x8fFmvQezE0JY/T9fX18h/en8+fNCpVIJIYTYt2+f6NevX6VcNzc3t1KuU50lJiYKT09PodPpRHp6umjXrp04evSoUBRFxMfHmz0ew98FW3f+/HnRvn17IYQQeXl5omXLlmLjxo1i3LhxIj8/X+Tl5Yl+/fqJH3/8UQghRGpqqhBCiIyMDKFSqcSNGzeEEEIAYtOmTZa5iUoGJIpynq2yBlAFzZw5k7Nnz6JWq5k+fTo6nY7Q0FDatm1LWFgYonB2d1JSEt26dcPX15fevXtz5coVAMLDw4mOjgbAzc2NGTNm0KFDB7755huL3VNVkKrLZtN/d9O73wDq1KmDs7MzQ4cOJS4ujscff5xOnTpZOkSblKrLJvliGnUbNaFhw4b8/PPP/PDDD7Rv356EhAT9zx06dODUqVOcPn0agEWLFuHj40OnTp24ePGifru9vT3Dhg2z5C2ZjZwHUAXNnTuXlJQUNBoNsbGxDBo0iOPHj9O0aVOCgoI4ePAgAQEBTJo0iW3btuHq6sqmTZuYNWsWq1atKnG9hg0bcvToUQvcSdVRlMX0dsLv5Ny9TVfNZQaqm+n316lTx2Kx5ebmEhYWxtGjR1GpVIwZM4Zly5axdetWAHbv3s3nn3/Oli1bLBajqRhml83Jz2fA00OJjIzkjz/+YMyYMezdu5e33nqLV155pdh5sbGx7Nmzh/j4eGrXrk1ISAhZWVkAODk5YW9vX9rbVTuyBlANdOzYkebNm2NnZ4darUar1fLrr7+SkpJCz549UavVzJkzh0uXLpV6/ogRI8wccdVimMWUR9ty59d4pm08woWrN9myZQvBwcEWje/XX39lwoQJnDx5knr16nH8+HFOnTrF9evXAVi9ejVjxoyxaIymYJxdNisnn+23m/Htzu9ISEigd+/e9O7dm1WrVqHT6QC4fPky165d4/bt2zRo0IDatWtz6tQpDh8+bOG7sYxKqQEoirIK6A9cE0J4Fm57BNgEuAFa4FkhxC2lIKH7p8AzQAYQLoSQXz8rwHAhFUOOjn/OqrW3tyc3NxchBCqVqkKdWJb89loVGK576/hoK5w9e3Bh1VS6b6nFa+NfoUGDBhaNr0WLFgQFBQHw4osvsmjRIkaOHMm6desYPXo08fHxfPXVVxaN0RRKW4+4poMjbQOCeKJ5Y+zt7enVqxcnT54kMDAQKOjgXbduHX369GHp0qV4eHjQpk0bm22+q6wmoEhgCWD4WzYT2CuEmKsoyszC1zOAvkDrwn8BwBeF/5XKYVjVzdKlcTs1rdzj27Rpw/Xr14mPjycwMJCcnBx+++03VCqVmSIGrVZL//79SUlJMdt7moLxurf1Og7hb0HDimUxNfc9Gn4ZMF4kR1EURo8ezYABA3BycmL48OHUqFH9WnuNPxeAe3m5nDp2lA/fjdZvmzJlClOmTClx/nfffVfqdYtqC7agUpqAhBD7gZtGmwcBawp/XgMMNtj+VWEn9WHARVEUucBrOYyrujkOzmQ1bIVHOxXTp08v9ZyaNWsSHR3NjBkz8PHxQa1Wc+jQITNHXj1YWxbTbZrLBH0Uw4srfiJ0aTwXLlzQ1/TWr19Ply5daNq0KU2bNmXOnDmMHj3aInGamvHnoqRd4nbkBHr1fJrWrVtbOrwqodLWA1AUxQ3YYdAElCaEcCn8WQFuCSFcFEXZAcwVQhwo3LcXmCGESDS63svAywCPPfaY7++//14pcVZFyRfTeHHFT6Rn5+q31XWswbqxAfi0cLFgZOXTarX07duXLl26cOjQIZo1a8a2bdtYt24dy5Yt4969e7Rq1Yq1a9eSk5ODt7c358+fx87Ojrt379K2bVvOnTvHhQsXmDhxItevX6d27dosX7682EIx5lL0rduSWUyN11TIvX2V69+8y8Cnu5CSrKFdu3asXbuW2rVrs3HjRhYuXFjt27et4XOxVlaxHkDheNQHKmmEEMuEEH5CCD9XV1cTRVY1lFbVzcnPp3mDWhaKqOJOnz7NxIkTOX78OC4uLmzevJmhQ4eSkJBAcnIyHh4erFy5kvr166NWq/nxxx8B2LFjB71798bBwYGXX36ZxYsXk5SUxPz585kwYYJF7qWhsyM+LVws+pAxXlWtRv3GPDlxBW9HfMHJkyfZvHkztWvXBuDAgQOMGzfOUqGajTV8LlWVKRsGryqK0kQIcaWwieda4fbLQAuD45oXbpPKUFTVfdNguJs1L6Ri2D7t7u6OWq0GwNfXF61WS0pKCm+//TZpaWnodDp69+4NFIxG2rRpE0899RQbN25kwoQJ6HQ6Dh06xPDhw/XXz87OLvV9bUFFvwz4+vpSp04dPv74Y3OGJ1UxpiwAtgOjgLmF/91msP01RVE2UtD5e1sIccWEcVQLVWUhFcPO6oybV8gVf46ntre3JzMzk/DwcLZu3YqPjw+RkZHExsYCMHDgQP7xj39w8+ZNkpKS6N69O3fv3sXFxQWNRmOhO7IuFf0ykJSUZKEIpaqksoaBbgBCgEaKolwC3qXgwf+1oih/B34Hni08fCcFQ0DPUDAMtHr2UJmAtS+kYthZnUU+ubn5XL+TRaouu1jc6enpNGnShJycHKKiomjWrGBClbOzM/7+/kyZMoX+/ftjb29PvXr1cHd355tvvmH48OEIITh27Bg+Pj6Wuk2LqypfBiTrVykFgBDi+TJ29SjlWAFMrIz3laxLaeOylcLthg+pf/7znwQEBODq6kpAQADp6en6fSNGjGD48OH6WgFAVFQU48ePZ86cOeTk5PDcc8/ZdAEA1v9lQKoaKm0UkCn5+fmJxMTE+x8oWZTxCBUAJwe7YuPlJUkyH6sYBSTZBmsbLy9JUvmq3/RAyaJk+7QkVR2yBiBVOjkuu/oqbTEcDw8Pxo0bh0qlolevXmRmZgJw9uxZ+vTpg6+vL8HBwZw6dcrC0UvGZAEgVVvGKz7l5eURHh6Op6cnXl5efPLJJ5YOsUpJSkpi9erV/PTTTxw+fJjly5dz69atUif7AVYzgU8qm2wCkqqtVatW8cgjj5CZmYm/vz++vr5cvnxZn7gtLa38hHpSgaKJfd/vjWXIkCH67LFFi+GUNtlPTuCrGmQBIFUrhnlhFi9apF8E5eLFi9y7d49z584xadIk+vXrR69evUwWx6JFi/jiiy/o0KEDUVFRJnsfUzOc2Hft8G+EPF4y/YhxOvLMzEzy8/PlBL4qQDYBSdWGYZbM9uMX8vW2ncTHx5OcnEz79u3Jzs4mOTmZkJAQli5dytixY00Wy+eff87u3buLPfxzc3PLOcP6GGehtWvSjq3btnHx2i3u3r1b7mI4hhP4oGDt8eTkZHOGL1WALAAegrOzc6VcR6PRsHPnzkq5lq0qsTpUho4LdxUy8+31Kz7duHGD/Px8hg0bxpw5c0y2DOarr77KuXPn6Nu3L/Xr12fkyJEEBQUxcuRItFot3bt3x9vbmx49enDhwgWgYJ3m8ePH06lTJ1q2bElsbCxjxozBw8OD8PBwk8R5P8aJ5xwfbcUjPj15KrgzAQEBjB07ttzFcKKioli5ciU+Pj6oVCq2bdtW5rG2yLiPCgqeKbNmzdKvVXz16lWTxiAngj0EZ2fnSlk8IjIyksTERJYsWVIJUdkm45TZIjeHm1v/hatyB2+VB2lpaQwZMoQ1a9aQX5hM7d///jd9+/Y1STxubm76z/S///0vBw4coFatWgwYMIDQ0FBGjRrFqlWr2L59O1u3biU8PJysrCw2bNjA9u3bGTlyJAcPHkSlUuHv78/KlSv17ezmIif2mdbNmzeL9VH9+OOPNGrUiO3btzNgwADefPNN6tWrx9tvv/2X30NOBKskpZXWAFOnTkWlUtGjRw/9GqwajYZOnTrh7e3NkCFDuHXrFgAhISEUFWQ3btzAzc2Ne/fuMXv2bDZt2oRarWbTpk1muZ+0tDQ+//xzoGCB7P79+5vlfU3FOEumUsOBZs9/QMLPx9i6dSuxsbFMmTKFo0ePotFo0Gg0Jnv4Gxs4cCC1ahW0ncfHx/PCCy8AMHLkSA4cOKA/bsCAASiKgpeXF40bN8bLyws7OztUKhVardYssRqSE/sqX6oum+SLaaTqslm0aJH+m/7Fixc5ffo0NWvW1P8tFnWom5IsACpo1apVJCUlkZiYyKJFi0hNTeXu3bv4+flx/PhxunXrxvvvvw/ASy+9xEcffcSxY8fw8vLSby9NzZo1+eCDDxgxYgQajcZsC7QbFgDVgbU8rIr+wPMNatYVXXO5qDPVzs6uWMeqnZ2dxfoPBqqbcXBGd9aNDeDgjO4MVDezSBzVwf36qLKysnBwcNAv8Vm0vrcpyVFA5ShvRMnp06exs7PTP7BffPFFhg4dyu3bt0lLS6Nbt24AjBo1qthQOGsxc+ZMzp49i1qtxsHBgTp16hAaGkpKSgq+vr6sW7cORVFISkri9ddfR6fT0ahRIyIjI8nIyGD48OH6NvTTp08zYsQIk7WpV5SlZyEbjpi5cjuLXb+UzHLeuXNnNm7cyMiRI4mKiiqzE9WayMRzD884U25Who6bhX1UFwr7qCxBFgBlMPxjvn1Og3PKThLj46lduzYhISFkZWWVOMd4cW5jNWrU0Lc/l3a+Oc2dO5eUlBQ0Gg2xsbEMGjSI48eP07RpU4KCgjh48CABAQFMmjSJbdu24erqyqZNm5g1axarVq2ifv36aDQa1Go1q1evtpp1Zy31sDL+AxcC3ttxnKGOuRgOFVi8eDGjR48mIiICV1dXVq9ebfZYbUHnzp2tag1s40y5tdx9yUzehX97b7xVHnTq1MkicckCoBQVLa3z8/OJjo7mueee0y/GXb9+fRo0aEBcXBzBwcGsXbtWXxtwc3MjKSmJjh07Eh0drX+/unXrFkuJbI77O/G/O+Tl/9lM0bFjR5o3bw6AWq1Gq9Xi4uJCSkoKPXv2BCAvL48mTZoAMHbsWFavXs2CBQvYtGkTR44cMVv81sj4D7z5+FXUcqxB2NhpxdZtfvzxx4mJiSlxfmRkpP5nNzc3/WQ1431F0tLSWL9+PWaMxuEAACAASURBVBMmTCA2Npb58+ezY8eOyruhKs6aHv5Qdh+VcYe64aCS0NBQQkNDTRqX7AMohfHwt1ruvij5+fi392bmzJn60rpOnTocOXIET09PYmJimD17NgBr1qxh+vTpeHt7o9Fo9NunTZvGF198Qfv27blx44b++k899RQnTpwwSydwUTvk1E0/c+7GXbZrClbjNJ7Mk5ubixAClUql7zT95Zdf+OGHHwAYNmwY3333HTt27MDX15eGDRuaNG5rZ+51m6tbH05lKxqifeXKFbp27YparcbT05O4uDiLxGMtfVTGZA2gFH+ltDakVqtLbdNr27Ytx44d07+eM2cOAI888ggJCQmVFX6ZDGs2edQkLzuDNzcf46PO9qUe36ZNG65fv058fDyBgYHk5OTw22+/oVKpcHJyonfv3owfP56VK1eaPHZrZ+51mx+mD6eoFmcL1q9fT+/evZk1axZ5eXlkZGRYLBZL91GVRhYApahqi7BXlGEzhX2tejg2a4f2y/H8Y/sjuLdoWuL4mjVrEh0dzeTJk7l9+za5ubn83//9HyqVCoCwsDC2bNli0pQKVYk5/8Aftg+nuioauFHE39+fMWPGkJOTw+DBg80+l8KYtXWoywKgDNZYWj8s45qN68DpODnYsd+oZmM4IU2tVrN///5Sr3fgwAFGjx6NvX3pNQhbZKk/8Aftw6mODAduZNzLY7vmMgO7dmX//v18++23hIeH8/rrr/PSSy9ZOlSrIQuAclhbaf2wKrNmM2TIEM6ePVtqh6ZkOkXfcPPvFs+sWV4fTnx8vLnDNDvjgRsAb24+xmM17+LV5gnGjRtHdnY2R48elQWAAVkA2JjKqtkUzYmQzMfwG26WLo3bqeWnsy6vD6e6MR6FBeBgZ8d/d+3lxWeH4uDggLOzM1999ZUFo7Q+sgCwQdWtZmMLSnzDdXAmq2ErPNqpcK5Tm8aNG5c45359ONWJcfPmY69Hk5Ofz4SXx/DO6+MtGJl1k8ngJKkKME52B1DXsQbrxgYUm2dgy7ZrLpdo3rT11BX3SwYnawCSTdFqtfTv37/YRKvyxMbGUrNmTTp37mziyMpn7nkGVVF1HLhhanIimGRxRQ9XrVbL+vXrLRxNcbGxsVYxq9RaJhI988wzpKWllZiIZi0ZZRs6O+LTwkU+/CtIFgCSxRU9YM1VAOTm5hIWFoaHhwehoaFkZGTg5uamn52dmJhISEgIWq2WpUuX8sknn6BWqy02i7SINWTm3LlzJy4uLnImcjVhsQJAUZQ+iqL8qijKGUVRZloqDsnyiqbtz5w5k7i4ONRqNZ988onJ3u/XX39lwoQJnDx5knr16pX5IHNzc+PVV19l6tSpaDQaq8jcaepvuBERESxatAgoWOuie/fuAMTExBAWFqYvKA1nIk+fPh0omBkfGhpK27ZtCQsLoyr0L9o6ixQAiqLYA58BfYF2wPOKorSzRCyS9Zg7dy7BwcFoNBqmTp1aqdcuytN/6242LVq0ICgoCChI4224KIutCw4O1td0EhMT0el05OTkEBcXR9euXfXHzZ07lyeeeAKNRkNERAQAP//8MwsXLuTEiROcO3eOgwcPWuQepIqzVA2gI3BGCHFOCHEP2AgMslAskoUUPZRNzXAhjtCl8cWWOISCNN7mSNVt6Y7k8hR9Fm5tPElKSuLOnTs4OjoSGBhIYmKiPrtteYpmI9vZ2elnI0vWzVKjgJoBFw1eXwICDA9QFOVl4GWAxx57zHyRSWZR2rT9eiZ4H+Px87m5+Vz/4zK79v5Inx7d9Gm809PTSUpKom/fvmzevFl/ft26dblz506lxGINncmlMfwscvLzqevalMjISDp37oy3tzf79u3jzJkzeHh4lHud0mYjS9bNajuBhRDLhBB+Qgg/V1dXS4cjVSLDh3LRuPY3Nx8jz96x0tdFME7tDVCzYXMWf/YZHh4e3Lp1i/Hjx/Puu+8yZcoU/Pz8iuU2GjBgAFu2bKmUTuCivo7Y2FhCQkKsor3c+LPIysnnsuPjzIuIoGvXrgQHB7N06VLat29fbMEjc69hIZmGpQqAy0ALg9fNC7dJNqC0h7KDnR31m7XC3t4eHx+fSusENh4/X6N+Y9zHL+Orr9Zy8uRJNm/eTO3atQkODua3334jMTGR+fPnExsbC8CTTz7JsWPHKr0T2Fray0v7LOo+7sXVP/4gMDCQxo0b4+TkVOLeGzZsSFBQEJ6envpO4IoyHEFU3vDRsWPHcuLEiQe6tvRgLNUElAC0VhTFnYIH/3PACxaKpdrIzc2lRg3rn9tX1rR997/Vq/TkctaQ2ts4RTGUnr2zS5cuZoupSGkTzBzdfPjjlo46dQr+H/3222/6fYbt+sZDdkNCQvQ/G2aUNVZUAEyYMKHc2FasWHG/8KWHZJEagBAiF3gN+B44CXwthDhuiVisgVarpW3btoSHh/Pkk08SFhbGnj17CAoKonXr1hw5coSbN28yePBgvL296dSpk35hmffee4+RI0cSFBTEyJEjuX79OsOGDcPf3x9/f3+rHIlh7klNlhw/b9gBXdTXAdbTXm6JCWbGQ0jLGj4aEhJCYmIieXl5hIeH4+npiZeXl0mHCNsai31dFELsBHZa6v2tzZkzZ/jmm29YtWoV/v7+rF+/ngMHDrB9+3Y+/PBDWrRoQfv27dm6dSsxMTG89NJLaDQaAE6cOMGBAweoVasWL7zwAlOnTqVLly5cuHCB3r17c/LkSQvfXUnmnrZviQR4ZaUoLmsFNksx92dRkcVsDGtDGo2Gy5cv69N3pKWZfuSYrbD+9oJqzDC3u7u7O15eXgCoVCp69OiBoih4eXmh1Wr5/fff9aNTunfvTmpqqn50ysCBA6lVqyAnzJ49e4q1m965cwedTqfvgLQm1T0raVkpiq+n37NgVKUz12eRqsvmxP/ukJf/Z6f3/ZrDWrZsyblz55g0aRL9+vWTK9BVIlkAWEixYZA3r5Ar/vxWaGdnp28isLOzIzc3FwcHhzKvVadOHf3P+fn5HD58GCcnJ9MFX4bIyEh69epF06Yll5e0RWX1dQx5pidjn/2z47O89vLqpOh3Xty5hvbGXf3Q3/s1hzVo0IDk5GS+//57li5dytdff12tl7U0J6sdBlqdGQ+9y87N5487WaTqsss8Jzg4mKioKKBg5ESjRo2oV6/kyPlevXqxePFi/euiZiJziIyM5H//+5/Z3s/aWUsCN2tg+DufQU3ysjN4c/MxbmfevzZ048YN8vPzGTZsGHPmzOHo0aNmiNg2yBqABZTWNKAUbi/r4fDee+8xZswYvL29qV27NmvWrCn1uEWLFjFx4kS8vb3Jzc2la9euLF269C/FqdVq6du3L126dOHQoUM0a9aMbdu28euvv/Lqq6+SkZHBE088wapVq9i7dy+JiYmEhYVRq1Yt4uPj9c1StkymKC5g+DtvX6sejs3aof1yPP/Y/gjuLcqvMV6+fJnRo0frZ2r/+9//NkfINkEuCGMBqbpsgj6KKZaSwMnBjoNGi7NbmlarpVWrViQmJqJWq3n22WcZOHAg8+bNY/HixXTr1o3Zs2dz584dFi5cSEhICPPnz8fPr8z1JyQbVVV+56ub+y0II5uALMDamwYME6e5u7ujVqsB8PX15ezZs6SlpdGtWzcARo0axf79+y0ZrkTFJ1eVxdTNd9b+O2+rZBOQhVhr00B5ndP29vZyCJ6VqujkqrJERkbi6elp0g58a/2dt2WyBmBB1rZ6UUU6p+vXr0+DBg30eXHWrl2rrw1Uh/wwixYtwsPDg7CwMEuH8kAqOrnqgw8+wN/fH09PT15++WWEEERHR+v7b9RqNZmZmfd5t7/O2n7nq5O8vLwHPkcWAJJeaXlhijqnDa1Zs4bp06fj7e2NRqNh9uzZAISHh/Pqq6+a/CFiSp9//jm7d+/Wj7gqjzVluzTOz19WrqHXXnuNhIQEUlJSyMzMZMeOHYSGhuLn50dUVBQajUZ23lupwYMH4+vri0qlYtmyZUBBgsE33ngDHx8f4uPjWbduHR07dkStVvPKK6/c95qyCUjSKy1xmtsrX+gXHp82bZp+3+HDh0ucP2zYMIYNG2b6QE3k1Vdf5dy5c/Tt25fw8HDi4uI4d+4ctWvXZtmyZXh7e/Pee+9x9uxZzp07x2OPPcaGDRssHfYDTa7at28f8+bNIyMjg5s3b6JSqRgwYIClQpcewKpVq3jkkUfIzMzE39+fYcOGcffuXQICAvj44485efIkH330EQcPHsTBwaGoObBhedeUBYCkZw2J0yxp6dKl7Nq1i3379vH+++9XKPWGpT3I5KqsrCwmTJhAYmIiLVq04L333jPZ4jdS5SjKFtC8QS0WL1rEli1bALh48SKnT5/G3t5e/6Vr7969JCUl4e/vD1BUCy/3j1cWAFIxttpRp0/LUdhWfuDAgQql3rAkwz6bPIPJVWXlGip62Ddq1AidTkd0dDShoaFA9ei/qW4MB2TcPqfBOWUnifHx1K5dm5CQELKysnByctKvXyGEYNSoUcXmSSiKUu7QLlkASCVU9xw9xgz/0K7czmLXL1fKPd4w9YYlPejkKhcXF8aNG4enpyePPvqo/psi/Nl/IyfxWQfjRIJZGTpu3lXIzLfnwqlTpTbB9ujRg0GDBjF16lT+9re/cfPmTYCa5b2PLAAkm2b8hyYEvLfjON07dSYqKop33nmn3NQblmTcZ+M6cDpODnbsN5pcZZhraM6cOcyZM6fEtap6/011Y5wtoJa7L5nJu/Bv7423yoNOnTqVOKddu3bMmTOHXr16kZ+fX5Q/rOwkYsgCQLJxZWXsfHHCNBa8M/W+qTdMYePGjZw9e5ZZs2aVe5yt99lUZ8aFu1LDgWbPf1Bi5rROpyt23ogRIxgxYsSf5ynK3fLeR6aCkGyaNaQouHfvHjk5OfqmpVGjRjF58mR8fX3veywU7yiUD//qY7vmconC/UEXM5KpICSpHJZMUXDy5EneeOMN2rRpo192UQiBRqOhQ4cO/Pjjj6jVatRqNe3btyc9PZ1bt26hUql45ZVXSEhI0N+DnFxV/ZhlJTshhNX/8/X1FZJkSjfSs4Tmwi1xIz3LpO+j0+nEqlWrRFBQkAgKChIrVqwQd+7c0e9PSkoSI0eOFEII0b9/f3HgwAEhhBDp6ekiJydHCCFEVlaW2LBhg+jZs6dQq9Xi008/FampqSaN2xa98847Yvfu3SW279u3T/Tr188CET04IFGU82yVNQDJqmi1Wjw9Pc3+vqb+Fl2UYO/RJk1YuXIlK1as4MCBA/z973+nbt26+uN27dpF3759AQgKCuL1119n0aJFpKWlUaNGQZedo6Mjzz33HD/88APbtm1jz549NG3aVK7FUMk++OADnn76aUuHYVKyAJAkEzNcGN6l/wyo8whDhw7lgw8+4Pfffy927A8//KBf8nDmzJmsWLGCzMxMgoKCOHXqlP64a9eu8fHHHzNgwADy8vJYv349jRs3Nut9VUV3796lX79++Pj44OnpyaZNm0rNjwQFQ2Ojo6OBgoK5bdu2dOjQgf/85z+WvIVKJQsAyerk5eUxbtw4VCoVvXr1IjMzk+XLl+Pv74+Pjw/Dhg0jIyMDgG+++QZPT098fHzo2rWrhSMvyTjBnv1jam50HM+27/ZQv359Bg0axNNPP41Wq+X27dvk5ubSsGHB7P2zZ8/i5eXFjBkz8Pf359SpU9y+fZvBgwfTtWtXsrKy2LlzJ99++y1Dhw7VTwiSyrZr1y6aNm1KcnIyKSkp9OnTp9T8SIaysrIYN24c//3vf0lKSuKPP/6wUPSVTxYAktU5ffo0EydO5Pjx47i4uLB582aGDh1KQkICycnJeHh4sHLlSqCgmv7999+TnJzM9u3bLRx5SaUl2HOwsyPDrjZTpkxBo9Hw4YcfYm9vz+7du4s1OSxcuBBPT0+8vb1xcHDQNw1NnjyZkydPMmvWLJo1M0HHYDXm5eXF7t27mTFjBnFxcdSvX599+/YREBCAl5cXMTExHD9+vNg5p06dwt3dndatW6MoCi+++KKFoq98NlEAzJ49m4ULF+pfz5o1i08//ZTp06fj6emJl5cXmzZtAkoupvHaa68RGRlp7pBtTnmL0Gi1WlJSUggODsbLy4uoqCj9H2lQUBDh4eEsX778L6XDNTXj8dwAOfn5+gR7UJC4rUWLFuzatYs+ffroty9evJiUlBSOHTvGhg0bcHR0pH79+nTv3h1FUcx2Dw/qww8/tHQIJRT9fjVs+jhHjx7Fy8uLt99+mw8++IAJEyYQHR3NL7/8wrhx42wqP5JNFABjxozhq6++AiA/P5+NGzfSvHlzNBoNycnJ7Nmzh+nTp3PlSvkpACTTMGwjD10azz2jRWhyc3MJDw9nyZIl/PLLL7z77rv6P9KlS5cyZ84cLl68iK+vL6mpqZa6jVI9yDDTFStWlDrDs6qxtgLA8Pcr4O1viDl9ixdffJHp06frF5g3zI9krG3btmi1Ws6ePQtgFRlgK0u1nwmcqsvmtr0L9Vwa8PPPP3P16lXat2/PgQMHeP7557G3t6dx48Z069aNhIQEq5vuX90Zp2LIzc3neuEiNIYPyfT0dJo0aUJOTg5RUVH6po+zZ88SEBBAQEAA3333HRcvXtS3oVuL6pxgb/DgwVy8eJGsrCymTJnCuXPnyMzMRK1Wo1KpKrSugikZ/35l/u8cYQPf4f3G9XByrMkXX3zB1q1bS82PVMTJyYlly5bRr18/ateuTXBwcLVJnFetCwDDJF+pLv7MjlhC7TwdY8aMYffu3aWeU6NGDfINquy2VB20hNJSMRQtQmP4oPznP/9JQEAArq6uBAQE6P8Ap0+fzunTpxFC0KNHD3x8fMx9CxVSXRPsGeeo//HHH1myZIk+dballcip09KXv3kEsG5sAD4tXADw8/MrNT+SYdNvnz59io3Cqi4eqgBQFGU48B7gAXQUQiQa7HsL+DuQB0wWQnxfuL0P8ClgD6wQQsx9mBjKYlzyOzzRie9XvUbTeg6sX7+erKwsvvzyS0aNGsXNmzfZv38/ERER5OTkcOLECbKzs8nMzGTv3r106dLFFCFKPNgiNOPHjy9xfnUakleVFKWfiPpiAd9/+1/gzxz11qQifTC27GFrACnAUOBLw42KorQDngNUQFNgj6IoTxbu/gzoCVwCEhRF2S6EOPGQcZRgXPIr9g44u/vQvWNr7O3tGTJkCPHx8fj4+KAoCvPmzePRRx8F4Nlnn8XT0xN3d3fat29f2aFJBmRCs6qnqGadfeEXrsZsYc3X2xge2Eqfo96ayN+v8j1UASCEOAmUNiJhELBRCJENnFcU5QzQsXDfGSHEucLzNhYeW+kFgHHJL0Q+GZdO8eqKeRTFHBERQURERIlz582bx7x58yo7JKkM1bmNvLoxrFln6NLBsQ7v7DxNi5oZ+hz1Dg4O5OTkFKUjtjj5+1U2U40CagZcNHh9qXBbWdtLUBTlZUVREhVFSbx+/foDB2A4+sLhzmWuLHuZPj2fpqNa9cDXkkxPJjQzDWdn51K3L126VD8yrjTGw6GLGM5rqOXui8jPR7v0Fd76x1v6EUwvv/wy3t7ehIWFVcIdVA75+1W6+9YAFEXZAzxayq5ZQohtlR9SASHEMmAZFKSD/ivXKFbyzxslP3wLee+993B2di7Wng8FeX/69+9PSkqKhSKzXa+++upfOs+wZq3UcKDxs+/j5GBHtEH67JCQED766KNKi1UynfvWAIQQTwshPEv5V97D/zLQwuB188JtZW03GVnyS9VZREQEixYtAmDq1Kl0794dgJiYGP038FmzZuHj40OnTp24evUqUFAoz58/H4AzZ87w9NNP4+PjQ4cOHfTj3XU6HaGhobRt25awsDCEEBZNny1VPlM1AW0HnlMUxVFRFHegNXAESABaK4ririhKTQo6iq1v/r6Nu99DZcOGDXh5eeHp6cmMGTP05xk2N0RHRxMeHl7i2klJSfj4+ODj48Nnn31m2hupRGU1pVhacHAwcXFxACQmJqLT6cjJySEuLo6uXbty9+5dOnXqRHJyMl27dmX58uUlrhEWFsbEiRNJTk7m0KFDNGnSBICff/6ZhQsXcuLECc6dO8fBgwcBM+Wpl8zioQoARVGGKIpyCQgEvlUU5XsAIcRx4GsKOnd3AROFEHlCiFzgNeB74CTwdeGxkhUp76Hy5JNPMmPGDGJiYtBoNCQkJLB169YKX3v06NEsXryY5ORkU4VvE4pSG7i18SQpKYk7d+7g6OhIYGAgiYmJxMXFERwcTM2aNfVt+UVpNQylp6dz+fJlhgwZAhRMeqpduzZQkKKiefPm2NnZoVari50ra9bVw0MVAEKILUKI5kIIRyFEYyFEb4N9/xJCPCGEaCOE+M5g+04hxJOF+/71MO9fldzvW/UPP/xAYGAgHTp0YPjw4SXW+jSHijxUXFxcCAkJwdXVlRo1ahAWFsb+/fsrdP20tDTS0tL0WTtHjhxpytt5IH+1KUWr1dK9e3e8vb3p0aMHFy5cMHmshqkNQhbEUde1KZGRkXTu3Jng4GD27dvHmTNn8PDwwMHBQT9KryitRkU5Ov75cH/Qc6WqwSZyAVmD8r5Ve3t7M2fOHPbs2cPRo0fx8/NjwYIFZo2vog8VNze3Mq9hOBzY2saD389fbUqZNGkSo0aN4tixY4SFhTF58mSTxmmcXjorJ5/Ljo8zLyKCrl27EhwczNKlS2nfvn2FEsbVrVuX5s2b62tx2dnZ+lTbUvUnCwAzSNVlU+NvT5CQmFjqt+patWpx4sQJgoKCUKvVrFmzpsRCIaaOr6IPlY4dO/Ljjz9y48YN8vLy2LBhA926dQOgcePGnDx5kvz8fLZs2VLifVxcXHBxceHAgQMAFs8TAw/flBIfH88LL7wAFNRoiu7NVEpLL133cS+u/vEHgYGBNG7cGCcnJ4KDgyt8zbVr17Jo0SK8vb3p3Llztcp3L5WvWucCsgaG+YiuU5835iykc+fOeHt7679Vu7u707NnT4tlGSwtH0/dx724FP81gYGB1KlTR/9QadKkCXPnzuWpp55CCEG/fv0YNGgQAHPnzqV///64urri5+dXajPW6tWrGTNmDIqi6Fe+shTDzyYnP79Yrcfw83nYppTKVFpqA0c3H/64paNOnYImm6IF5oFin0FoaCihoaFAwSigIq1btyYmJqbYNVu2bElISIj+9ZIlSyrrFiQrohQtf2bN/Pz8RGJi4v0PtDKpumyCPoohK6fgDzbtQBR3f9nDpnWRBHX0xd/fH19fX5YtW4avry8xMTG0atWKu3fvcvnyZZ588sn7vINp4gRwcrDjoMHY7uqmtHvWHVqP0/n9RK5ejZeXl/7z2bJlC87OzvqHaXR0NDt27CAyMpKBAwcyfPhwRo4cSWRkJNu2bSu19lOZtmsul0htIEfiSKVRFCVJCOFX1n5ZAzAh42/Wjs1V3I7/mqZP+hSrqru6uhIZGcnzzz9PdnY2AHPmzDFbAWCL+VIepNZTnsWLFzN69GgiIiJwdXVl9erVpg5dpjaQKo2sAZhQVftmXZTh0RYeKlXts5Gkv+J+NQDZCWxCVW3WpC2N7a5qn40kmYKsAZiBLX2zrmrkZyNVZ7IPwApU19WgqgP52Ui2TDYBSZIk2ShZAEiSJNkoWQBIkiTZKFkAYL2pfiVJkkxJFgCSJEk2ShYAkiRJNkoWAJJkZgsWLMDT0xNPT08WLlyIVqvFw8ODcePGoVKp6NWrF5mZmZYOU7IBNl0AFKUCliRzSUpKYvXq1fz0008cPnyY5cuXc+vWLU6fPs3EiRM5fvw4Li4ubN682dKhVthbb73Fvn372Lp1K//+97+L7fv1118ZNWoU+fn5BAYGlnr+U089RVZWFv/3f/9HfHx8if1ffvklq1evRqPR8Morr5g0FltjswWA4QIoGffy2K4x6dr0ko0r+rLx/d5YhgwZQp06dXB2dmbo0KHExcXh7u6OWq0GSl+60Zr99NNPdOrUiR9//FG/2luRogV1fvnlFzw9PUucm5mZiZ2dHU5OTiQkJODnV3LSatE1Srt+ZcZii2xyJrDhAihF2SDf3HyMoFaN5KxQqdIZrjtw7fBvhDxeq8QxxssvVoUmoOnTp/P9999z/vx5AgMDOXv2LHv37iU0NJSnnnqKSZMmceHCBRo3bkx6ejp2dnb4+flRlNblqaee4uLFi6Snp+Pl5cXvv/+Ov78/H374Ic888wyffPIJa9as4fTp06SkpKDVamnatClxcXEsXbq0UmOxWUIIq//n6+srKpPmwi3hOXuXeHzGDvH4jB1CcXASnrN3Cc2FW5X6PpJ0Iz1LtHl7p/537dFRC0XNv7mJC1dvCp1OJ1QqlTh69KhQqVT6cyIiIsS7775ruaAfwJEjR8Rrr70m7t27Jzp37lxif6dOnUR+fr4IDw8XKSkpJfbPmzdPREdHi9jYWDFt2rQS+69duyb69+8vhBDC39/fpLFUR0CiKOfZapNNQMarKj32ejQ5+fk0b1Dym5kkPQzjJRwdH23FIz49eSq4MwEBAYwdO5YGDRpYMMIHV9SclarL5ujRo/j4+HDq1Ck8PDyKHZeRkYGjoyOKonD69GnatGlT4lpF5x87dgwfH58y99+5cwcXFxeTxmKLbDYbqFxVSTKH6rbuQFFzVu6181za9jE1s2/RtPHfyMjIQAhBw4YNiY+PZ8SIEZw6dYq0tDQeffRRtFotLVu25K233mLEiBGsWLGCJUuWcObMGVq1aqVvnunQoQNRUVFcu3aNXr16ce3aNZycnLCzsyM9PZ0mTZqwefNmnnjiiUqLpTq7XzZQmy0AQKYClsyjunzZKK0wuxo1nQvHk5g+eTxvvvkm7dq10++LiIigZcuWNGzYkJ07dzJv3rxi17t27Rpjx45l+/btdOzYkSNHjpR4y1qIrAAAC/RJREFUz/79+xMZGcmSJUvo2LEjzzzzjEliqa5kOuhyyFTAkjlUlyUcjZfRzMu4TQ0nZ/53O5tTp04Ve+AC7N+/n5deeolly5bRrVu3Etfbv38/Xbp04eLFizz++OMl9ufl5ZGamkqjRo04dOgQr7/+uslisVU2XQOQJKnirKk5y5pisWZySUjJZkRGRvK///3P0mFUW9a0jKY1xVKVPVQTkKIoEcAA4B5wFhgthEgr3PcW8HcgD5gshPi+cHsf4FPAHlghhJj7MDFIUpHIyEg8PT1p2rSppUOptqypOcuaYqmqHqoJSFGUXkCMECJXUZSPAIQQMxRFaQdsADoCTYE9wJOFp/0G9AQuAQnA80KIE+W9j2wCsl0LFixg1apVAIwdO5bBgwfTv39/UlJSAJg/fz46nQ5PT0/Cw8Np1qwZtWrVIj4+nlq15LBeybaZtAlICPGDECK38OVhoHnhz4OAjUKIbCHEeeAMBYVBR+CMEOKcEOIesLHwWEkqoay8OaUJDQ3Fz8+PqKgoNBqNfPhLUgVUZh/AGOC7wp+bARcN9l0q3FbW9hIURXlZUZRERVESr1+/XolhSlVBqi6bTf/dTe9+A0rkzZEkqXLctw9AUZQ9wKOl7JolhNhWeMwsIBeIqqzAhBDLgGVQ0ARUWdeVrF/RBJ/bCb+Tc/c2XTWX9ePm09LSyDeYxZ2VlWWpMCWpyrtvDUAI8bQQwrOUf0UP/3CgPxAm/uxQuAy0MLhM88JtZW2XJKB4oj4ebcudX+OZtvEIF67eZMuWLfTt25dr166RmppKdnY2O3bs0J9bt25d0tPTLRi9JFUtDzsKqA/wJtBNCJFhsGs7sF5RlAUUdAK3Bo4ACtBaURR3Ch78zwEvPEwMUvViOMHH8dFWOHv24MKqqXTfUovXxr+Cv78/s2fPpmPHjjRr1oy2bdvqzw0PD+fVV1+VncCSVEEPOwroDOAIpBZuOiyEeLVw3ywK+gVygf8TQnxXuP0ZYCEFw0BXCSH+db/3kaOAbIec4CNJlUfmApKqnOqSO0eSLE3mApKqHDnBR5LMQxYAklWSifokyfRkLiBJkqo9Uy9cX1XJAkCSpGrP1AvXV1WyCUiSpGrL1AvXV3VyFJAkSdVaQkICX331FQsWLCAkJISDBw8W2x8YGMihQ4cYM2YM06ZNQ6VSFdtftJpYo0aN2LFjBxEREeYM/6HI9QAkSbIphgvFAyZfuL4qk01AklQNpKam0qNHDwD++OMP7O3tcXV1RavV0rRpU06cKDfjerVRlEfKwc6O9P+dxm7/F9xJvUqjRo30i8Wr1eoSi8V7e3uj1Wrx8/MrdeH6kydP6puKvvvuO6KiKi3tmUXJJiBJqmbee+89nJ2dmTZtGlqtttj6CdVZWbPI6/3wAYfjDzJmzBiTLFxvzWQTkCTZuLy8PMaNG4dKpaJXr15kZmYCcPbsWfr06YOvry/BwcGcOnXKwpE+nKI8UoaUzDs4OtfFzs6uzMXiu3TpQlxc3F9auL6qkzUASapmjGsArVq1IjExEbVazbPPPsvAgQN58cUX6dGjB0uXLqV169b89NNPvPXWW8TExFg6/L9M5pEqSaaCkKRqLlWXXW7aDHd3d9RqNQC+vr5otVp0Oh2HDh1i+PDh+uOys7PNFrMpFC0Ub5xHylYf/hUhCwBJqsIMOz2LHnjGHB3/fADa29uTmZlJfn4+Li4u/H979x9b1VnHcfz9gZZ2kfUHOCdCHZeETAeRH5nLjKYpm7JKzHDJTECJaP1LY8Q/yIIhmSzL/pgSQ0wkxASSmTSuwjQwomxMaQxLxlz0FqsMuUyWbXagzq7TOij26x/nufX07ralw55zbs/3lZzwnO9zb/K5zeE+5zzPaU+xWEwy7ozzvyM1Pb4G4HLlwoUL437bc/fu3ezatYuOjg62bdvG6tWrWblyZU0s9sUfnvPW5au8PTLKA0+cZvjK1Snf29TURKFQ4ODBgwCYGX19fTMdOREL5zewqq3Fv/yvgQ8AzgXDw8MUi0X27t1LV1dX2nGmVG3Rs37OHIb+PfUAANDd3c3+/ftZtWoVK1as4PDhwzMR02WYTwG5XCjPk4/+a+J57s2bNwPQ3t7O0NAQg4ODtLS0JBVx2pa03sBI7PnIACOjozzy8ENjZ79Lly4ddwvo9u3bx9qFQoFjx44lE9Zlkg8AbtaLz5MPD17iyvCVsb74Q+UljXtf5X7W+KKnu14+ALhZLT5P/jaj2LwmBl6/yLmX/8IH37+Qo0eP0tnZCUBPTw/r1q3j5MmTNDc309zcnHL6qfmip7sePgC4WS3+kHkAza3jfe2f5672j1O4pW3cQ+UbGxtZs2YNIyMjHDhwIK3I0+YPz3Hvlg8AblarNk/e9NF7efbQnnFfmh0dHWzZsoU9e/YkHdG51PhdQG5WK8+TN9bP4caGOhrr5/g8uXOBXwG4We9a5sl7e3uTD+ZcynwAcLng8+TOvZNPATnnXE75AOCccznlA4BzzuWUDwDOOZdTPgA451xO1cQTwST9FXg57RzAe4G/pR1imjzzzKu1vOCZk5J25lvM7KaJOmtiAMgKSS9M9ni1LPLMM6/W8oJnTkrWM/sUkHPO5ZQPAM45l1M+AEzPD9MO8C545plXa3nBMycl05l9DcA553LKrwCccy6nfABwzrmc8gGgCkkPSzotqSjpaUkfCHVJ+r6kUuhfG3vPVknnwrY1hczflfRiyPUzSS2xvm+FzGcl3ROrd4ZaSdKOFDJ/TtIfJI1Kur2iL5OZK2UtT5mkA5IuSeqP1RZIOh6O0eOSWkN9wuM6wbxtkk5I+mM4JrbVQOZGSc9L6guZHwr1gqRTIVuPpHmh3hD2S6F/adKZ38HMfKvYgKZY+xvAvtDeAPwCEHAncCrUFwAvhX9bQ7s14czrgbrQfhR4NLRvA/qABqAAnAfmhu08sAyYF15zW8KZPwzcCvQCt8fqmc1ckT9TeSqytQNrgf5Y7TvAjtDeETtGqh7XCeddBKwN7RuBP4XjIMuZBcwP7XrgVMjyE2BTqO8DvhraX4t9l2wCetI+TvwKoAozG4rtvgcor5RvBH5kkeeAFkmLgHuA42b2hpn9AzgOdCac+Wkzuxp2nwOWxDI/bmaXzezPQAm4I2wlM3vJzK4Aj4fXJpn5jJmdrdKV2cwVspZnjJn9GnijorwReCy0HwM+G6tXO64TY2YDZvbb0H4LOAMsznhmM7N/ht36sBlwF3Bogszlz3IIuFuSEopblQ8AE5D0iKRXgC8AD4byYuCV2MteDbWJ6mnpIjo7gtrJHFcrmbOWZyo3m9lAaL8O3BzamfocYWpkDdEZdaYzS5orqQhcIjrxOw8Mxk7G4rnGMof+N4GFySYeL7cDgKRnJPVX2TYCmNlOM2sDuoGvp5s2MlXm8JqdwFWi3Km7lswueRbNQ2TuHnBJ84EngG9WXIlnMrOZ/cfMVhNdcd8BfCjlSNOS20dCmtknr/Gl3cDPgW8DrwFtsb4lofYa0FFR773ukBWmyizpS8BngLvDfxaYODOT1P9vpvFzjks18zRMljOLLkpaZGYDYbrkUqhn4nNIqif68u82s5+GcqYzl5nZoKQTwMeIpqPqwll+PFc586uS6oBm4O+pBA5yewUwGUnLY7sbgRdD+wjwxXAHwp3Am+Hy9ClgvaTWcJfC+lBLMnMn8ABwr5kNx7qOAJvCHQgFYDnwPPAbYHm4Y2Ee0aLUkSQzT6JWMmctz1SOAOU71LYCh2P1asd1YsJc+H7gjJl9L9aV5cw3KdxtJ+kG4FNEaxcngPsnyFz+LPcDv4qdqKUj7VXoLG5EZyH9wGngSWCx/W/V/wdE83y/Z/ydK11Ei5Ul4MspZC4RzS8Ww7Yv1rczZD4LfDpW30B0t8V5YGcKme8jmiO9DFwEnsp65iqfIVN5Yrl+DAwAI+Fn/BWi+eZfAueAZ4AF4bUTHtcJ5v0E0fTO6dgxvCHjmT8C/C5k7gceDPVlRCcsJeAg0BDqjWG/FPqXpX2c+J+CcM65nPIpIOecyykfAJxzLqd8AHDOuZzyAcA553LKBwDnnMspHwCccy6nfABwzrmc+i92j0dg/X9EsgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}