{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=img/MScAI_brand.png width=70%></center>\n",
    "\n",
    "# High-Performance Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The purpose of this notebook is to provide the basic terminology and concepts of high-end/high-performance computing. If you already know what these are, you can skip it!\n",
    "* Threads versus processes\n",
    "* Distributed versus parallel computing\n",
    "* GPUs\n",
    "* Taskfarming\n",
    "* Profilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python and HPC\n",
    "Python is slow, but it's still used for (some) HPC! Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Numpy can move many inner loops to C or Fortran\n",
    "* \"Just-in-time\" compilation with Numba, Cython, PyPy, etc. \n",
    "* Deep learning uses GPUs, Python uses GPU libraries\n",
    "* Python is slower than C only by a (multiplicative) constant. Getting the right algorithm remains more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GPUs\n",
    "\n",
    "<center><img src=img/GPU-images.png width=60%></center>\n",
    "\n",
    "\n",
    "Aa **graphics processing unit** is a specialised processor for graphics, especially video games. A GPU is specialised for processing large numerical matrices. Many AI and numerical computing problems run very effectively on GPUs!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=img/nvidia-fission-GPU.png width=60%></center>\n",
    "    \n",
    "* Deep learning is always on GPUs, except for toy problems\n",
    "* Cryptocurrency <a href=https://www.sciencedaily.com/releases/2019/06/190613104533.htm>:-(</a>\n",
    "* Weather simulations, nuclear simulations, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributed versus parallel computing\n",
    "\n",
    "\n",
    "Parallel computing: running multiple things at once on a single machine (especially with multiple CPUs on a single machine)\n",
    "\n",
    "Distributed computing: running one thing across multiple machines, usually with message-passing between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parallel computing \n",
    "\n",
    "<center><img src=img/serial-parallel-processing.png width=60%></center>\n",
    "             \n",
    "<font size=1>https://www.explainthatstuff.com/how-supercomputers-work.html</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parallel computing with threads and processes\n",
    "\n",
    "Threads and processes are two similar concepts. They both involve multiple parts of a program running in parallel (on a single machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Every program, when it runs, becomes a **process**\n",
    "* A program may **fork** to become multiple processes\n",
    "* A program may also create multiple **threads**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Threads are more \"lightweight\" (easier/quicker to start and stop threads than processes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we have multiple CPUs, then multiple processes or multiple threads can take advantage of that.\n",
    "\n",
    "Even if we have a single CPU, multiple processes or threads can be useful. (They don't really run in **parallel**, but the OS gives that illusion by interleaving their work, and it can still help a lot!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "* Any program with a GUI will have at least a back-end process and a GUI process or thread. Even when the back-end process is busy processing, the GUI remains responsive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A web server typically launches a new thread for every incoming request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Some optimisation algorithms can run multiple processes or threads, e.g. all running in parallel, to take advantage of multiple CPUs, e.g.~`GridSearchCV` has a parameter `n_jobs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Communication between threads and/or processes is a complex topic and causes many bugs :-/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using multiple cores -- the hard way\n",
    "\n",
    "Take our program, and rewrite it to use multiple processes and/or threads with communication between them. When it runs, the OS will put each process/thread on separate cores in a fairly smart/adaptive way. We'll get a speedup, but probably sublinear :-("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using multiple cores -- the easy way\n",
    "\n",
    "If we need to run our program **multiple times** and we have **multiple cores** (and if each run won't use up too much RAM), then don't rewrite the program. Just run it multiple times at once. E.g. if we have 4 cores, open up 4 terminals and type `python myprog.py` in each one. We'll probably get a 4x speedup :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a bit too **manual** for large-scale tasks (e.g. many runs on multiple machines). **Taskfarming** takes this to a logical conclusion: we put our commands into a file and hand it to a specialised taskfarming program. It decides how many to run in parallel, and takes care of starting the next one whenever a task finishes (to ensure CPU utilisation) etc. \n",
    "\n",
    "It can even use multiple machines if available. \n",
    "\n",
    "In the next notebook/video we'll see how this is used on ICHEC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributed computing\n",
    "\n",
    "<center><img src=img/HPC-images.png width=80%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In distributed computing, we have multiple machines running a single job, so usually they need to communicate during the job. This is outside our scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Understanding performance in terms of bottlenecks\n",
    "\n",
    "When a program is too slow, there are many possible reasons:\n",
    "* Slow CPU\n",
    "* Not enough RAM causes the machine to move data from RAM to disk and back often (\"thrashing\")\n",
    "* Wrong algorithm (e.g. \"accidentally quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And many possible solutions:\n",
    "\n",
    "* Buy a bigger computer or a GPU\n",
    "* Use parallel and/or distributed computing\n",
    "* Find a better algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=img/bottleneck.jpg width=50%></center>\n",
    "<font size=1>https://www.kissclipart.com/manufacturing-bottleneck-clipart-bottleneck-busine-0xtdag/</font>\n",
    "\n",
    "A **bottleneck** model is useful for thinking about performance. Usually when a program is slow, there's one main reason why it's slow, e.g. just one function or one inner loop. That's the only place where an optimisation effort can yield any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before trying to optimise a function, we should find out **which functions** are using most of the time in our program! \n",
    "\n",
    "That's the job of the **profiler**. A profiler is a tool that runs your program and tells you where it spends most of its time. It gives a report like this, telling us how often each function is called and the total time spent in each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=6>\n",
    "    \n",
    "```python\n",
    "      \n",
    "197 function calls (192 primitive calls) in 0.002 seconds\n",
    "\n",
    "Ordered by: standard name\n",
    "\n",
    "ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "     1    0.000    0.000    0.001    0.001 <string>:1(<module>)\n",
    "     1    0.000    0.000    0.001    0.001 re.py:212(compile)\n",
    "     1    0.000    0.000    0.001    0.001 re.py:268(_compile)\n",
    "     1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)\n",
    "     1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)\n",
    "     4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)\n",
    "   3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)\n",
    "```\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python has a built-in profiler: https://docs.python.org/3/library/profile.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sophisticated understanding of algorithms and engineering and budget trade-offs might be needed! You could pay a developer to make your algorithm use less RAM, but it might be cheaper to just buy a load of extra RAM. You could implement a Hadoop solution, but it might be better to just <a href=https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html>learn to use basic tools properly</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have barely scratched the surface here, but you can see more in **Tools and Techniques for Large-Scale \n",
    "Data Analytics** in Semester 2. \n",
    "\n",
    "For now, we'll assume that our program is reasonably well-optimised, and we want to run it multiple times with different hyperparameters, so a possible solution is to use **taskfarming** on a large compute server with multiple CPUs (maybe even multiple machines) and/or machines with GPUs. That's what we'll study next."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
