{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=img/MScAI_brand.png width=70%></center>\n",
    "\n",
    "# Scikit-Learn: Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pipelines\n",
    "\n",
    "Often, we'll have several preprocessing steps and then our main model. For example, we might have a data with missing values which would also benefit from having the square of each feature -- ideas we discussed in the previous notebook/video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[ np.nan, 0,   3  ],\n",
    "              [ 3,   7,   9  ],\n",
    "              [ 3,   5,   2  ],\n",
    "              [ 4,   np.nan, 6  ],\n",
    "              [ 8,   8,   1  ]])\n",
    "y = np.array([14, 16, -1,  8, -5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pipelines\n",
    "* A *pipeline* is sequence of Scikit-Learn estimators\n",
    "* Each transforms the `X`\n",
    "* All but the last must have `transform()`: its output becomes the input of the next `fit()` and `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=img/sklearn_pipeline.svg width=80%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "* **Convenience and encapsulation**: Call `fit` and `predict` just once\n",
    "* **Joint parameter selection**: grid search over parameters of pipeline components together\n",
    "* **Safety**: avoid errors leaking test data into training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                      PolynomialFeatures(degree=2),\n",
    "                      LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('simpleimputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('polynomialfeatures',\n",
       "                 PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is equivalent to writing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "X = SimpleImputer(strategy=\"mean\").fit_transform(X)\n",
    "X = PolynomialFeatures(degree=2).fit_transform(X)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `ColumnTransformer`\n",
    "\n",
    "Often we'll want to transform some columns with e.g. one-hot encoding, and others with e.g. missing value imputation, and leave other columns alone. \n",
    "\n",
    "See [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reference\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Confirm that our trained `model` can handle `np.nan` transparently and makes sensible predictions, by passing in a query point in the *original* format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "We mentioned that \"convenience and encapsulation\" are part of the motivation for using pipelines. One situation where this is especially true is when we are *saving* models to disk. Scikit-Learn doesn't provide its own method for this, but instead uses the `pickle` module built-in to the standard library. For any object `c`, we can write:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "pickle.dump(c, open(\"data/my_object.pkl\", \"wb\"))\n",
    "# later...\n",
    "c2 = pickle.load(open(\"data/my_object.pkl\", \"rb\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. We have to open the file ourselves -- we  pass a `file` object, not a filename, to `dump` and to `load`.\n",
    "2. We have to read/write using *binary mode* (`\"wb\"` and `\"rb\"`) because the pickle format is binary, not plain-text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, the exercise is to save our trained Scikit-Learn pipeline model to disk, and then read it in again. Confirm that the model we read in from disk gives the same results as the model we wrote to disk.\n",
    "\n",
    "See https://scikit-learn.org/stable/tutorial/basic/tutorial.html#model-persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 3 \n",
    "\n",
    "Check how large is the model saved on disk, e.g. using `ls` on Unix or `dir` on Windows. For the curious: how does the size compare to a bare LR model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.91644421])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[ np.nan, 0.5, 3.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.91644421])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "model = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                      PolynomialFeatures(degree=2),\n",
    "                      LinearRegression())\n",
    "model.fit(X, y)\n",
    "pickle.dump(model, open(\"data/LR_pipeline.pkl\", \"wb\"))\n",
    "model2 = pickle.load(open(\"data/LR_pipeline.pkl\", \"rb\"))\n",
    "model2.predict([[ np.nan, 0.5, 3.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solution 3\n",
    "\n",
    "For me, the file is 1252 bytes:\n",
    "```\n",
    "$ ls -l LR_pipeline.pkl\n",
    "-rw-r--r--  1 jmmcd  staff  1252 28 Oct 19:18 LR_pipeline.pkl\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
